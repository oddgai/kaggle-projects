# exp002 - 過学習対策強化版モデル

## 概要

exp001で発生したCVスコア(84.96%)とKaggleスコア(77.27%)のギャップ(7.7%)を解決するため、LightGBMの過学習対策を強化したモデル。同じ特徴量を使用し、パラメータ調整に特化。

## exp001からの変更点

### ハイパーパラメータの過学習対策強化

| パラメータ | exp001 | exp002 | 変更理由 |
|---|---|---|---|
| `num_leaves` | 31 | **15** | モデル複雑度を大幅削減 |
| `learning_rate` | 0.05 | **0.03** | より慎重な学習 |
| `feature_fraction` | 0.9 | **0.7** | 特徴量サブサンプリング強化 |
| `min_data_in_leaf` | - | **50** | 各葉の最小サンプル数制約 |
| `lambda_l1` | - | **0.1** | L1正則化項追加 |
| `lambda_l2` | - | **0.1** | L2正則化項追加 |
| `min_gain_to_split` | - | **0.1** | 分割に必要な最小ゲイン |

## 使用した特徴量

exp001と同じ16個の特徴量を使用：

### 基本特徴量
- `Pclass` - チケットクラス
- `Sex` - 性別  
- `Age` - 年齢（称号による欠損値補完済み）
- `SibSp` - 同乗した兄弟姉妹・配偶者の数
- `Parch` - 同乗した親・子供の数
- `Fare` - 運賃（中央値で欠損値補完済み）
- `Embarked` - 乗船港

### エンジニアリング特徴量
- `Title` - 名前から抽出した称号
- `FamilySize` - 家族サイズ
- `IsAlone` - 一人旅フラグ
- `FamilySizeGroup` - 家族サイズのカテゴリ化
- `AgeBin` - 年齢のビニング
- `FareBin` - 運賃のビニング
- `HasCabin` - 客室情報の有無
- `Sex_Pclass` - 性別とクラスの組み合わせ
- `HasTicketPrefix` - チケット番号にプレフィックスがあるか

## 検証結果

### 単一検証
- **検証精度**: 0.8212 (82.12%)

### 5-fold クロスバリデーション
- **CV平均スコア**: 0.8462 (84.62%)
- **標準偏差**: ±0.0356

### Kaggle提出結果
- **Public Score**: 0.76315 (76.32%)

### 特徴量重要度（上位5つ）
1. **Sex_Pclass**: 2543 - 性別×クラス組み合わせ（最重要）
2. **Sex**: 1144 - 性別
3. **Age**: 751 - 年齢
4. **Fare**: 658 - 運賃
5. **Title**: 406 - 称号

## exp001との比較

| 指標 | exp001 | exp002 | 改善効果 |
|---|---|---|---|
| 検証精度 | 82.12% | **82.12%** | 変化なし |
| CV平均スコア | 84.96% | **84.62%** | -0.34% |
| CV標準偏差 | ±2.63% | **±3.56%** | 悪化 |
| Kaggle Score | 77.27% | **76.32%** | -0.95% |
| CVとKaggleの差 | 7.69% | **8.30%** | 悪化 |

## 出力ファイル

### 提出ファイル
- `../../results/exp002/submission.csv`
- 形式: PassengerId, Survived

### 予測統計
- **テスト予測生存者数**: 147人
- **テスト予測死亡者数**: 271人
- **テスト予測生存率**: 35.17%

## 結果分析

### 過学習対策の効果

**期待した効果**
- CVとKaggleスコアのギャップ縮小
- モデルの安定性向上

**実際の結果**
- ❌ **CVとKaggleのギャップが拡大** (7.69% → 8.30%)
- ❌ **CV標準偏差が悪化** (±2.63% → ±3.56%)
- ❌ **Kaggleスコアが低下** (77.27% → 76.32%)

### 失敗の原因分析

1. **過度の正則化**: パラメータを変更しすぎてモデルの表現力が低下
2. **データサイズとの不整合**: Titanicの小規模データには過度な制約
3. **特徴量と正則化のミスマッチ**: 現在の特徴量セットには元のパラメータが適していた

## 実装のポイント

### 技術的特徴
- exp001との直接比較が可能な構造
- 同一条件での公平な比較
- パラメータ変更の影響を明確に分離

### 学習した教訓
- **小規模データでは過度な正則化が逆効果**
- **パラメータ調整は段階的に行うべき**
- **CVスコアの改善とKaggleスコアの改善は必ずしも一致しない**

## 次の改善案

### 1. より慎重なパラメータ調整
- 一度に多くのパラメータを変更せず、1つずつ検証
- `num_leaves`は25程度から開始
- 正則化パラメータはより小さな値から開始

### 2. 異なるアプローチ
- ハイパーパラメータチューニングよりも特徴量改善を優先
- アンサンブル手法の導入
- 異なるアルゴリズムとの組み合わせ

### 3. より詳細な分析
- 学習曲線の詳細分析
- 誤分類サンプルの特徴分析
- 特徴量重要度の変化の詳細検討

## 派生元
- exp001 - ベースラインモデル（過学習対策前）

## 備考
- 過学習対策が必ずしも改善につながらないことを実証
- 小規模データセットでのパラメータ調整の難しさを体験
- 次回は特徴量改善や異なる手法を検討予定