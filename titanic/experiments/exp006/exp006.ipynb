{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp006 - ã€ŒLess is Moreã€ã«ã‚ˆã‚‹ç²¾å¯†æœ€é©åŒ–\n",
    "\n",
    "exp005ã®å¤±æ•—ï¼ˆéå­¦ç¿’ï¼‰ã‚’å—ã‘ã¦ã€ã‚·ãƒ³ãƒ—ãƒ«åŒ–ã¨ç²¾å¯†æœ€é©åŒ–ã«ã‚ˆã‚‹å …å®Ÿãªæ”¹å–„ã‚’ç›®æŒ‡ã™\n",
    "\n",
    "## æˆ¦ç•¥\n",
    "1. **ç‰¹å¾´é‡å‰Šæ¸›**: 45å€‹ â†’ 15-18å€‹\n",
    "2. **å˜ä¸€ãƒ¢ãƒ‡ãƒ«é›†ä¸­**: LightGBMã®ã¿\n",
    "3. **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–**: Optunaæ´»ç”¨\n",
    "4. **æ±åŒ–æ€§èƒ½é‡è¦–**: CV vs Kaggleä¹–é›¢ç›£è¦–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "\n",
    "print(\"ğŸ¯ exp006 - Less is Moreæˆ¦ç•¥é–‹å§‹\")\n",
    "print(f\"LightGBM: {lgb.__version__}\")\n",
    "print(f\"Optuna: {optuna.__version__}\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "train_df = pd.read_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/data/train.csv')\n",
    "test_df = pd.read_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/data/test.csv')\n",
    "\n",
    "print(f\"\\nTrain shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: æº–å‚™ãƒ»åˆ†æï¼ˆexp004ç‰¹å¾´é‡é‡è¦åº¦åˆ†æï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp004ã¨åŒã˜ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆæ¯”è¼ƒã®ãŸã‚ï¼‰\n",
    "def exp004_feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # åå‰ã‹ã‚‰ã®ç‰¹å¾´é‡\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
    "        'Mlle': 'Miss', 'Countess': 'Rare', 'Ms': 'Mrs', 'Lady': 'Rare',\n",
    "        'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Mrs',\n",
    "        'Capt': 'Rare', 'Sir': 'Rare'\n",
    "    }\n",
    "    df['Title_Grouped'] = df['Title'].map(title_mapping).fillna('Other')\n",
    "    df['Name_Length'] = df['Name'].str.len()\n",
    "    \n",
    "    # è‹—å­—ã¨å®¶æ—ã‚µã‚¤ã‚º\n",
    "    df['Surname'] = df['Name'].str.split(',').str[0]\n",
    "    all_surnames = pd.concat([train_df['Name'], test_df['Name']]).str.split(',').str[0]\n",
    "    surname_counts = all_surnames.value_counts()\n",
    "    df['Surname_Count'] = df['Surname'].map(surname_counts)\n",
    "    \n",
    "    # ãƒã‚±ãƒƒãƒˆç‰¹å¾´é‡\n",
    "    df['Ticket_Length'] = df['Ticket'].str.len()\n",
    "    df['Ticket_IsNumeric'] = df['Ticket'].str.isnumeric().astype(int)\n",
    "    df['Ticket_Prefix'] = df['Ticket'].str.extract(r'^([A-Za-z]+)').fillna('NUMERIC')\n",
    "    \n",
    "    all_tickets = pd.concat([train_df['Ticket'], test_df['Ticket']])\n",
    "    ticket_counts = all_tickets.value_counts()\n",
    "    df['Ticket_Count'] = df['Ticket'].map(ticket_counts)\n",
    "    \n",
    "    # å®¢å®¤ç‰¹å¾´é‡\n",
    "    df['HasCabin'] = (~df['Cabin'].isnull()).astype(int)\n",
    "    df['Cabin_Deck'] = df['Cabin'].str.extract(r'^([A-Za-z])').fillna('Unknown')\n",
    "    df['Cabin_Number'] = df['Cabin'].str.extract(r'(\\d+)').astype(float)\n",
    "    df['Cabin_Count'] = df['Cabin'].fillna('').str.split().str.len()\n",
    "    df.loc[df['Cabin'].isnull(), 'Cabin_Count'] = 0\n",
    "    \n",
    "    # åŸºæœ¬å‰å‡¦ç†\n",
    "    df['Sex_Binary'] = df['Sex'].map({'female': 0, 'male': 1})\n",
    "    df['Age'] = df.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    # å®¶æ—æ§‹æˆ\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df['IsSmallFamily'] = ((df['FamilySize'] >= 2) & (df['FamilySize'] <= 4)).astype(int)\n",
    "    df['IsLargeFamily'] = (df['FamilySize'] > 4).astype(int)\n",
    "    \n",
    "    # å¹´é½¢ãƒ»é‹è³ƒã‚°ãƒ«ãƒ¼ãƒ—\n",
    "    df['Age_Group'] = pd.cut(df['Age'], bins=[0, 12, 18, 25, 35, 50, 65, 100], \n",
    "                           labels=['Child', 'Teen', 'Young', 'Adult', 'Middle', 'Senior', 'Elder'])\n",
    "    df['Fare_Group'] = pd.qcut(df['Fare'], q=8, labels=['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8'])\n",
    "    \n",
    "    # åŸºæœ¬äº¤äº’ä½œç”¨\n",
    "    df['Sex_Pclass'] = df['Sex_Binary'] * df['Pclass']\n",
    "    df['Age_Fare_Interaction'] = df['Age'] * df['Fare']\n",
    "    df['Age_FamilySize'] = df['Age'] * df['FamilySize']\n",
    "    \n",
    "    # çµ±è¨ˆç‰¹å¾´é‡\n",
    "    df['Age_Rank_SexPclass'] = df.groupby(['Sex_Binary', 'Pclass'])['Age'].rank(pct=True)\n",
    "    df['Fare_Rank_Pclass'] = df.groupby('Pclass')['Fare'].rank(pct=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# exp004ç‰¹å¾´é‡ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç¢ºèª\n",
    "print(\"=== Step 1: exp004ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ ===\")\n",
    "train_processed = exp004_feature_engineering(train_df)\n",
    "test_processed = exp004_feature_engineering(test_df)\n",
    "\n",
    "print(f\"exp004ç‰¹å¾´é‡æ•°: {train_processed.shape[1] - train_df.shape[1]}å€‹ï¼ˆè¿½åŠ åˆ†ï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "categorical_features = ['Embarked', 'Title_Grouped', 'Cabin_Deck', 'Ticket_Prefix', 'Age_Group', 'Fare_Group']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in train_processed.columns:\n",
    "        le = LabelEncoder()\n",
    "        all_categories = pd.concat([train_processed[feature], test_processed[feature]]).astype(str)\n",
    "        le.fit(all_categories)\n",
    "        \n",
    "        train_processed[feature] = le.transform(train_processed[feature].astype(str))\n",
    "        test_processed[feature] = le.transform(test_processed[feature].astype(str))\n",
    "\n",
    "# exp004ç›¸å½“ã®ç‰¹å¾´é‡é¸æŠ\n",
    "exclude_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived', 'Surname', 'Title', 'Sex']\n",
    "exp004_features = [col for col in train_processed.columns \n",
    "                  if col not in exclude_features and \n",
    "                  train_processed[col].dtype in ['int64', 'float64', 'int32', 'float32']]\n",
    "\n",
    "X_full = train_processed[exp004_features]\n",
    "y = train_processed['Survived']\n",
    "X_test_full = test_processed[exp004_features]\n",
    "\n",
    "print(f\"exp004ç›¸å½“ç‰¹å¾´é‡æ•°: {len(exp004_features)}\")\n",
    "print(\"\\nexp004ç‰¹å¾´é‡ä¸€è¦§:\")\n",
    "for i, feat in enumerate(exp004_features, 1):\n",
    "    print(f\"{i:2d}. {feat}\")\n",
    "\n",
    "# é‡è¦åº¦å–å¾—ã®ãŸã‚ç°¡æ˜“ãƒ¢ãƒ‡ãƒ«è¨“ç·´\n",
    "print(\"\\nç‰¹å¾´é‡é‡è¦åº¦åˆ†æã®ãŸã‚ç°¡æ˜“LightGBMè¨“ç·´...\")\n",
    "lgb_params_simple = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "feature_importance_scores = np.zeros(len(exp004_features))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_full, y)):\n",
    "    X_train, X_val = X_full.iloc[train_idx], X_full.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        lgb_params_simple,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        num_boost_round=500,\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    feature_importance_scores += model.feature_importance()\n",
    "\n",
    "# å¹³å‡é‡è¦åº¦è¨ˆç®—\n",
    "feature_importance_scores /= 5\n",
    "\n",
    "# é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': exp004_features,\n",
    "    'importance': feature_importance_scores\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== exp004ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° ===\")\n",
    "for i, row in importance_df.iterrows():\n",
    "    print(f\"{importance_df.index.get_loc(i)+1:2d}. {row['feature']:20s}: {row['importance']:8.1f}\")\n",
    "\n",
    "# é‡è¦åº¦å¯è¦–åŒ–\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('é‡è¦åº¦')\n",
    "plt.title('exp004ç‰¹å¾´é‡é‡è¦åº¦ Top 15')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\né‡è¦åº¦åˆ†æå®Œäº†ã€‚æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å‰Šæ¸›å€™è£œã‚’æ±ºå®šã—ã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: æ®µéšçš„ç‰¹å¾´é‡å‰Šæ¸›å®Ÿé¨“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 2: æ®µéšçš„ç‰¹å¾´é‡å‰Šæ¸›å®Ÿé¨“ ===\")\n",
    "\n",
    "# å‰Šæ¸›æˆ¦ç•¥ã®è¨­å®š\n",
    "def create_feature_sets(importance_df, exp004_features):\n",
    "    \"\"\"\n",
    "    é‡è¦åº¦ã«åŸºã¥ã„ã¦æ®µéšçš„ãªç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’ä½œæˆ\n",
    "    \"\"\"\n",
    "    # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆçµ¶å¯¾ã«æ®‹ã™ï¼‰\n",
    "    core_features = ['Sex_Binary', 'Pclass', 'Age', 'Fare']\n",
    "    \n",
    "    # é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã®ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ\n",
    "    sorted_features = importance_df['feature'].tolist()\n",
    "    \n",
    "    # å„æ®µéšã®ç‰¹å¾´é‡ã‚»ãƒƒãƒˆå®šç¾©\n",
    "    feature_sets = {\n",
    "        '20features': {\n",
    "            'features': sorted_features[:20],\n",
    "            'description': 'é‡è¦åº¦ä¸Šä½20ç‰¹å¾´é‡'\n",
    "        },\n",
    "        '18features': {\n",
    "            'features': sorted_features[:18], \n",
    "            'description': 'é‡è¦åº¦ä¸Šä½18ç‰¹å¾´é‡'\n",
    "        },\n",
    "        '15features': {\n",
    "            'features': sorted_features[:15],\n",
    "            'description': 'é‡è¦åº¦ä¸Šä½15ç‰¹å¾´é‡'\n",
    "        },\n",
    "        '12features': {\n",
    "            'features': sorted_features[:12],\n",
    "            'description': 'é‡è¦åº¦ä¸Šä½12ç‰¹å¾´é‡ï¼ˆæ”»ã‚ã®å‰Šæ¸›ï¼‰'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # ã‚³ã‚¢ç‰¹å¾´é‡ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª\n",
    "    for set_name, set_info in feature_sets.items():\n",
    "        missing_core = [f for f in core_features if f not in set_info['features']]\n",
    "        if missing_core:\n",
    "            print(f\"âš ï¸ {set_name}ã«ã‚³ã‚¢ç‰¹å¾´é‡{missing_core}ãŒä¸è¶³\")\n",
    "    \n",
    "    return feature_sets\n",
    "\n",
    "# ç‰¹å¾´é‡ã‚»ãƒƒãƒˆä½œæˆ\n",
    "feature_sets = create_feature_sets(importance_df, exp004_features)\n",
    "\n",
    "# å„ã‚»ãƒƒãƒˆã®å†…å®¹è¡¨ç¤º\n",
    "for set_name, set_info in feature_sets.items():\n",
    "    print(f\"\\n{set_name} ({set_info['description']}):\")\n",
    "    for i, feat in enumerate(set_info['features'], 1):\n",
    "        importance = importance_df[importance_df['feature'] == feat]['importance'].iloc[0]\n",
    "        print(f\"{i:2d}. {feat:20s} ({importance:6.1f})\")\n",
    "\n",
    "print(\"\\nç‰¹å¾´é‡ã‚»ãƒƒãƒˆå®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§ã®æ€§èƒ½è©•ä¾¡\n",
    "def evaluate_feature_set(X, y, features, set_name, n_folds=5):\n",
    "    \"\"\"\n",
    "    æŒ‡å®šã•ã‚ŒãŸç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§CVæ€§èƒ½ã‚’è©•ä¾¡\n",
    "    \"\"\"\n",
    "    X_subset = X[features]\n",
    "    \n",
    "    # LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆexp004æº–æ‹ ï¼‰\n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    early_stop_rounds = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_subset, y)):\n",
    "        X_train, X_val = X_subset.iloc[train_idx], X_subset.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_data,\n",
    "            valid_sets=[val_data],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        val_pred = model.predict(X_val)\n",
    "        val_pred_binary = (val_pred >= 0.5).astype(int)\n",
    "        fold_score = accuracy_score(y_val, val_pred_binary)\n",
    "        cv_scores.append(fold_score)\n",
    "        early_stop_rounds.append(model.best_iteration)\n",
    "    \n",
    "    mean_cv = np.mean(cv_scores)\n",
    "    std_cv = np.std(cv_scores)\n",
    "    mean_early_stop = np.mean(early_stop_rounds)\n",
    "    \n",
    "    return {\n",
    "        'set_name': set_name,\n",
    "        'n_features': len(features),\n",
    "        'cv_mean': mean_cv,\n",
    "        'cv_std': std_cv,\n",
    "        'early_stop_mean': mean_early_stop,\n",
    "        'cv_scores': cv_scores\n",
    "    }\n",
    "\n",
    "# å…¨ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§è©•ä¾¡å®Ÿè¡Œ\n",
    "print(\"å„ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§ã®æ€§èƒ½è©•ä¾¡é–‹å§‹...\")\n",
    "\n",
    "evaluation_results = []\n",
    "for set_name, set_info in feature_sets.items():\n",
    "    print(f\"\\nğŸ“Š {set_name} è©•ä¾¡ä¸­...\")\n",
    "    result = evaluate_feature_set(X_full, y, set_info['features'], set_name)\n",
    "    evaluation_results.append(result)\n",
    "    \n",
    "    print(f\"CV: {result['cv_mean']:.4f} Â± {result['cv_std']:.4f}\")\n",
    "    print(f\"Early Stopå¹³å‡: {result['early_stop_mean']:.1f}ãƒ©ã‚¦ãƒ³ãƒ‰\")\n",
    "\n",
    "# çµæœæ¯”è¼ƒ\n",
    "print(\"\\n=== ç‰¹å¾´é‡å‰Šæ¸›çµæœæ¯”è¼ƒ ===\")\n",
    "print(f\"{'Set':15s} {'Features':8s} {'CV Mean':8s} {'CV Std':8s} {'Early Stop':10s} {'æœŸå¾…Kaggle':10s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# exp004åŸºæº–ã®æœŸå¾…Kaggleè¨ˆç®—ï¼ˆçµŒé¨“å¼ï¼‰\n",
    "exp004_cv = 0.8462\n",
    "exp004_kaggle = 0.77990\n",
    "cv_kaggle_ratio = exp004_kaggle / exp004_cv\n",
    "\n",
    "best_result = None\n",
    "best_score = 0\n",
    "\n",
    "for result in evaluation_results:\n",
    "    expected_kaggle = result['cv_mean'] * cv_kaggle_ratio\n",
    "    print(f\"{result['set_name']:15s} {result['n_features']:8d} {result['cv_mean']:8.4f} {result['cv_std']:8.4f} {result['early_stop_mean']:10.1f} {expected_kaggle:10.5f}\")\n",
    "    \n",
    "    # æœŸå¾…KaggleãŒæœ€é«˜ã®ã‚‚ã®ã‚’é¸æŠ\n",
    "    if expected_kaggle > best_score:\n",
    "        best_score = expected_kaggle\n",
    "        best_result = result\n",
    "\n",
    "print(f\"\\nğŸ† æœ€é«˜æ€§èƒ½ç‰¹å¾´é‡ã‚»ãƒƒãƒˆ: {best_result['set_name']}\")\n",
    "print(f\"ğŸ“Š CVæ€§èƒ½: {best_result['cv_mean']:.4f} Â± {best_result['cv_std']:.4f}\")\n",
    "print(f\"ğŸ¯ æœŸå¾…Kaggleã‚¹ã‚³ã‚¢: {best_score:.5f}\")\n",
    "\n",
    "# æœ€é©ç‰¹å¾´é‡ã‚»ãƒƒãƒˆæ±ºå®š\n",
    "optimal_features = feature_sets[best_result['set_name']]['features']\n",
    "print(f\"\\næœ€é©ç‰¹å¾´é‡æ•°: {len(optimal_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆOptunaï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 3: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ– ===\")\n",
    "print(f\"æœ€é©ç‰¹å¾´é‡ã‚»ãƒƒãƒˆ: {best_result['set_name']} ({len(optimal_features)}ç‰¹å¾´é‡)\")\n",
    "\n",
    "# æœ€é©åŒ–ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "X_optimal = X_full[optimal_features]\n",
    "X_test_optimal = X_test_full[optimal_features]\n",
    "\n",
    "print(\"\\nä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡:\")\n",
    "for i, feat in enumerate(optimal_features, 1):\n",
    "    importance = importance_df[importance_df['feature'] == feat]['importance'].iloc[0]\n",
    "    print(f\"{i:2d}. {feat:20s} ({importance:6.1f})\")\n",
    "\n",
    "# Optunaæœ€é©åŒ–é–¢æ•°å®šç¾©\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optunaã®ç›®çš„é–¢æ•°ï¼šCVç²¾åº¦ã‚’æœ€å¤§åŒ–\n",
    "    \"\"\"\n",
    "    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ç©ºé–“\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'random_state': 42,\n",
    "        \n",
    "        # ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 60),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        \n",
    "        # æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé‡ç‚¹çš„ã«æ¢ç´¢ï¼‰\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 2.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 2.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.001, 1.0)\n",
    "    }\n",
    "    \n",
    "    # 5-foldäº¤å·®æ¤œè¨¼\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    early_stop_counts = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_optimal, y):\n",
    "        X_train, X_val = X_optimal.iloc[train_idx], X_optimal.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[val_data],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        val_pred = model.predict(X_val)\n",
    "        val_pred_binary = (val_pred >= 0.5).astype(int)\n",
    "        fold_score = accuracy_score(y_val, val_pred_binary)\n",
    "        cv_scores.append(fold_score)\n",
    "        early_stop_counts.append(model.best_iteration)\n",
    "    \n",
    "    mean_cv = np.mean(cv_scores)\n",
    "    mean_early_stop = np.mean(early_stop_counts)\n",
    "    \n",
    "    # éå­¦ç¿’ã®å…†å€™ãŒã‚ã‚‹å ´åˆãƒšãƒŠãƒ«ãƒ†ã‚£\n",
    "    if mean_early_stop > 800:  # æ—©æœŸåœæ­¢ã—ãªã„å ´åˆ\n",
    "        mean_cv *= 0.99  # è»½ã„ãƒšãƒŠãƒ«ãƒ†ã‚£\n",
    "    \n",
    "    return mean_cv\n",
    "\n",
    "# Optunaæœ€é©åŒ–å®Ÿè¡Œ\n",
    "print(\"\\nOptunaæœ€é©åŒ–é–‹å§‹ï¼ˆ100å›è©¦è¡Œï¼‰...\")\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# æœ€é©åŒ–å®Ÿè¡Œ\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n=== æœ€é©åŒ–çµæœ ===\")\n",
    "print(f\"æœ€é«˜CVç²¾åº¦: {study.best_value:.4f}\")\n",
    "print(f\"æœ€é©åŒ–è©¦è¡Œæ•°: {len(study.trials)}\")\n",
    "\n",
    "print(\"\\næœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss', \n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "})\n",
    "\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"{param:20s}: {value}\")\n",
    "\n",
    "# æœŸå¾…Kaggleã‚¹ã‚³ã‚¢è¨ˆç®—\n",
    "expected_kaggle = study.best_value * cv_kaggle_ratio\n",
    "improvement_from_exp004 = expected_kaggle - exp004_kaggle\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æ”¹å–„åˆ†æ:\")\n",
    "print(f\"æœ€é©åŒ–å‰CV: {best_result['cv_mean']:.4f}\")\n",
    "print(f\"æœ€é©åŒ–å¾ŒCV: {study.best_value:.4f} ({study.best_value - best_result['cv_mean']:+.4f})\")\n",
    "print(f\"æœŸå¾…Kaggle: {expected_kaggle:.5f}\")\n",
    "print(f\"exp004ã‹ã‚‰: {improvement_from_exp004:+.5f} ({improvement_from_exp004/exp004_kaggle*100:+.2f}%)\")\n",
    "\n",
    "if improvement_from_exp004 > 0:\n",
    "    print(\"âœ… exp004ã‹ã‚‰ã®æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã‚‹ï¼\")\n",
    "else:\n",
    "    print(\"âš ï¸ exp004ã‹ã‚‰ã®æ”¹å–„ã¯é™å®šçš„\")\n",
    "\n",
    "print(\"\\nãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: æœ€çµ‚ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¨è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Step 4: æœ€çµ‚ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¨è©•ä¾¡ ===\")\n",
    "\n",
    "# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´\n",
    "print(\"æœ€çµ‚LightGBMãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹...\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "final_cv_scores = []\n",
    "oof_predictions = np.zeros(len(X_optimal))\n",
    "test_predictions = np.zeros(len(X_test_optimal))\n",
    "models = []\n",
    "feature_importance_final = np.zeros(len(optimal_features))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_optimal, y), 1):\n",
    "    print(f\"Fold {fold}/5 è¨“ç·´ä¸­...\")\n",
    "    \n",
    "    X_train, X_val = X_optimal.iloc[train_idx], X_optimal.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        best_params,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # äºˆæ¸¬\n",
    "    val_pred = model.predict(X_val)\n",
    "    test_pred = model.predict(X_test_optimal)\n",
    "    \n",
    "    val_pred_binary = (val_pred >= 0.5).astype(int)\n",
    "    fold_score = accuracy_score(y_val, val_pred_binary)\n",
    "    final_cv_scores.append(fold_score)\n",
    "    \n",
    "    # OOFäºˆæ¸¬ä¿å­˜\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    test_predictions += test_pred / 5\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ã¨é‡è¦åº¦ä¿å­˜\n",
    "    models.append(model)\n",
    "    feature_importance_final += model.feature_importance()\n",
    "    \n",
    "    print(f\"Fold {fold} Accuracy: {fold_score:.4f} (Rounds: {model.best_iteration})\")\n",
    "\n",
    "# æœ€çµ‚çµæœè¨ˆç®—\n",
    "final_cv_mean = np.mean(final_cv_scores)\n",
    "final_cv_std = np.std(final_cv_scores)\n",
    "oof_accuracy = accuracy_score(y, (oof_predictions >= 0.5).astype(int))\n",
    "feature_importance_final /= 5\n",
    "\n",
    "print(f\"\\n=== æœ€çµ‚ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ ===\")\n",
    "print(f\"CV Accuracy: {final_cv_mean:.4f} Â± {final_cv_std:.4f}\")\n",
    "print(f\"OOF Accuracy: {oof_accuracy:.4f}\")\n",
    "\n",
    "# exp004ãƒ»exp005ã¨ã®æ¯”è¼ƒ\n",
    "print(f\"\\n=== å®Ÿé¨“æ¯”è¼ƒ ===\")\n",
    "print(f\"exp004 CV: 0.8462 Â± 0.034\")\n",
    "print(f\"exp005 CV: 0.8507 Â± 0.012 (éå­¦ç¿’)\")\n",
    "print(f\"exp006 CV: {final_cv_mean:.4f} Â± {final_cv_std:.4f}\")\n",
    "\n",
    "cv_improvement_004 = final_cv_mean - 0.8462\n",
    "print(f\"\\nexp004ã‹ã‚‰ã®CVæ”¹å–„: {cv_improvement_004:+.4f}\")\n",
    "\n",
    "# æœŸå¾…Kaggleæ€§èƒ½\n",
    "final_expected_kaggle = final_cv_mean * cv_kaggle_ratio\n",
    "kaggle_improvement_004 = final_expected_kaggle - exp004_kaggle\n",
    "\n",
    "print(f\"\\nğŸ¯ æœŸå¾…æ€§èƒ½:\")\n",
    "print(f\"æœŸå¾…Kaggle: {final_expected_kaggle:.5f}\")\n",
    "print(f\"exp004ã‹ã‚‰: {kaggle_improvement_004:+.5f} ({kaggle_improvement_004/exp004_kaggle*100:+.2f}%)\")\n",
    "\n",
    "if kaggle_improvement_004 > 0.005:\n",
    "    print(\"ğŸ‰ å¤§å¹…æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã‚‹ï¼\")\n",
    "elif kaggle_improvement_004 > 0:\n",
    "    print(\"âœ… æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã‚‹\")\n",
    "else:\n",
    "    print(\"âš ï¸ æ”¹å–„ã¯é™å®šçš„\")\n",
    "\n",
    "# æœ€çµ‚ç‰¹å¾´é‡é‡è¦åº¦\n",
    "final_importance_df = pd.DataFrame({\n",
    "    'feature': optimal_features,\n",
    "    'importance': feature_importance_final\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\n=== æœ€çµ‚ç‰¹å¾´é‡é‡è¦åº¦ ===\")\n",
    "for i, row in final_importance_df.iterrows():\n",
    "    print(f\"{final_importance_df.index.get_loc(i)+1:2d}. {row['feature']:20s}: {row['importance']:8.1f}\")\n",
    "\n",
    "# é‡è¦åº¦å¯è¦–åŒ–\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(final_importance_df)), final_importance_df['importance'])\n",
    "plt.yticks(range(len(final_importance_df)), final_importance_df['feature'])\n",
    "plt.xlabel('é‡è¦åº¦')\n",
    "plt.title(f'exp006æœ€çµ‚ç‰¹å¾´é‡é‡è¦åº¦ ({len(optimal_features)}ç‰¹å¾´é‡)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ã¨æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ\n",
    "test_predictions_binary = (test_predictions >= 0.5).astype(int)\n",
    "\n",
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_processed['PassengerId'],\n",
    "    'Survived': test_predictions_binary\n",
    "})\n",
    "\n",
    "# çµæœä¿å­˜\n",
    "import os\n",
    "os.makedirs('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/results/exp006', exist_ok=True)\n",
    "submission.to_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/results/exp006/result.csv', index=False)\n",
    "\n",
    "print(f\"\\n=== æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº† ===\")\n",
    "print(f\"ç”Ÿå­˜äºˆæ¸¬æ•°: {test_predictions_binary.sum()}\")\n",
    "print(f\"æ­»äº¡äºˆæ¸¬æ•°: {len(test_predictions_binary) - test_predictions_binary.sum()}\")\n",
    "print(f\"äºˆæ¸¬ç”Ÿå­˜ç‡: {test_predictions_binary.mean():.3f}\")\n",
    "print(f\"\\nå®Ÿéš›ç”Ÿå­˜ç‡: {y.mean():.3f}\")\n",
    "print(f\"äºˆæ¸¬vså®Ÿéš›: {test_predictions_binary.mean() - y.mean():+.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«: results/exp006/result.csv\")\n",
    "\n",
    "# äºˆæ¸¬åˆ†å¸ƒå¯è¦–åŒ–\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(oof_predictions, bins=50, alpha=0.7, label='OOF Predictions')\n",
    "plt.axvline(0.5, color='red', linestyle='--', label='Threshold')\n",
    "plt.xlabel('äºˆæ¸¬ç¢ºç‡')\n",
    "plt.ylabel('é »åº¦')\n",
    "plt.title('OOFäºˆæ¸¬åˆ†å¸ƒ')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(test_predictions, bins=50, alpha=0.7, label='Test Predictions')\n",
    "plt.axvline(0.5, color='red', linestyle='--', label='Threshold')\n",
    "plt.xlabel('äºˆæ¸¬ç¢ºç‡')\n",
    "plt.ylabel('é »åº¦')\n",
    "plt.title('ãƒ†ã‚¹ãƒˆäºˆæ¸¬åˆ†å¸ƒ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp006 æœ€çµ‚ã‚µãƒãƒªãƒ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"                ğŸ¯ EXP006 æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nğŸ“Š å®Ÿé¨“è¨­å®š:\")\n",
    "print(f\"æˆ¦ç•¥: Less is Moreï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ– + ç²¾å¯†æœ€é©åŒ–ï¼‰\")\n",
    "print(f\"ç‰¹å¾´é‡æ•°: {len(optimal_features)} (exp004: 23, exp005: 45)\")\n",
    "print(f\"ãƒ¢ãƒ‡ãƒ«: LightGBMå˜ä½“\")\n",
    "print(f\"æœ€é©åŒ–: Optuna 100å›è©¦è¡Œ\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æ€§èƒ½çµæœ:\")\n",
    "print(f\"CV Accuracy: {final_cv_mean:.4f} Â± {final_cv_std:.4f}\")\n",
    "print(f\"OOF Accuracy: {oof_accuracy:.4f}\")\n",
    "print(f\"æœŸå¾…Kaggle: {final_expected_kaggle:.5f}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ å®Ÿé¨“é€²æ—æ¯”è¼ƒ:\")\n",
    "experiments = [\n",
    "    ('exp001', 0.77272, 0.8496),\n",
    "    ('exp004', 0.77990, 0.8462),\n",
    "    ('exp005', 0.76315, 0.8507),\n",
    "    ('exp006', '???', final_cv_mean)\n",
    "]\n",
    "\n",
    "for exp_name, kaggle, cv in experiments:\n",
    "    if exp_name == 'exp006':\n",
    "        print(f\"{exp_name}: Kaggle={kaggle}, CV={cv:.4f} â† ä»Šå›\")\n",
    "    else:\n",
    "        print(f\"{exp_name}: Kaggle={kaggle}, CV={cv:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š æ”¹å–„åˆ†æ:\")\n",
    "print(f\"exp004ã‹ã‚‰CVæ”¹å–„: {cv_improvement_004:+.4f} ({cv_improvement_004/0.8462*100:+.2f}%)\")\n",
    "print(f\"exp004ã‹ã‚‰æœŸå¾…Kaggleæ”¹å–„: {kaggle_improvement_004:+.5f} ({kaggle_improvement_004/exp004_kaggle*100:+.2f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ”§ å®Ÿè£…æˆæœ:\")\n",
    "print(f\"âœ… ç‰¹å¾´é‡å‰Šæ¸›: 23â†’{len(optimal_features)}ç‰¹å¾´é‡ï¼ˆ{23-len(optimal_features)}å€‹å‰Šæ¸›ï¼‰\")\n",
    "print(f\"âœ… ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–: Optuna 100å›è©¦è¡Œ\")\n",
    "print(f\"âœ… éå­¦ç¿’åˆ¶å¾¡: CVæ¨™æº–åå·®{final_cv_std:.4f}ï¼ˆå®‰å®šæ€§ç¢ºä¿ï¼‰\")\n",
    "print(f\"âœ… æ±åŒ–æ€§èƒ½é‡è¦–: æœŸå¾…ä¹–é›¢{abs(final_cv_mean - final_expected_kaggle):.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ¨ ä¸»è¦æ”¹å–„è¦å› :\")\n",
    "print(f\"1. æˆ¦ç•¥çš„ç‰¹å¾´é‡å‰Šæ¸›ï¼ˆé‡è¦åº¦ãƒ™ãƒ¼ã‚¹ï¼‰\")\n",
    "print(f\"2. LightGBMç²¾å¯†æœ€é©åŒ–ï¼ˆæ­£å‰‡åŒ–é‡è¦–ï¼‰\")\n",
    "print(f\"3. Less is MoreåŸç†ã®å®Ÿè·µ\")\n",
    "print(f\"4. æ±åŒ–æ€§èƒ½ã‚’é‡è¦–ã—ãŸè¨­è¨ˆ\")\n",
    "\n",
    "print(f\"\\nğŸ† ä½¿ç”¨ç‰¹å¾´é‡ Top 5:\")\n",
    "for i, row in final_importance_df.head(5).iterrows():\n",
    "    print(f\"{final_importance_df.index.get_loc(i)+1}. {row['feature']:20s}: {row['importance']:8.1f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ exp006ã®å­¦ã³:\")\n",
    "if kaggle_improvement_004 > 0:\n",
    "    print(f\"ğŸ‰ ã‚·ãƒ³ãƒ—ãƒ«åŒ–æˆ¦ç•¥ãŒæˆåŠŸï¼\")\n",
    "    print(f\"ğŸ“ˆ ç‰¹å¾´é‡ã®è³ª > é‡ ã®å®Ÿè¨¼\")\n",
    "    print(f\"âš–ï¸ æœ€é©åŒ–ã¨æ±åŒ–ã®ãƒãƒ©ãƒ³ã‚¹\")\n",
    "else:\n",
    "    print(f\"ğŸ“š æ”¹å–„ãŒé™å®šçš„ã ãŒé‡è¦ãªå­¦ç¿’\")\n",
    "    print(f\"ğŸ” Titanicãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§ç†è§£æ·±åŒ–\")\n",
    "    print(f\"âš™ï¸ æœ€é©åŒ–æ‰‹æ³•ã®å®Ÿè·µç¿’å¾—\")\n",
    "\n",
    "print(f\"\\nğŸ¯ æ¬¡ã®å®Ÿé¨“ã¸ã®ç¤ºå”†:\")\n",
    "if final_cv_mean > 0.850:\n",
    "    print(f\"ãƒ»ç¾åœ¨ã®æ‰‹æ³•ã§é«˜ã„æ€§èƒ½ã‚’é”æˆ\")\n",
    "    print(f\"ãƒ»ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆç•°ãªã‚‹ç‰¹å¾´é‡ã‚»ãƒƒãƒˆï¼‰ã§æ›´ãªã‚‹å‘ä¸Š\")\n",
    "else:\n",
    "    print(f\"ãƒ»Neural Networkã®å°å…¥æ¤œè¨\")\n",
    "    print(f\"ãƒ»å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿æ´»ç”¨ï¼ˆæ­´å²çš„äº‹å®Ÿï¼‰\")\n",
    "    print(f\"ãƒ»ã‚ˆã‚Šé«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸš€ exp006å®Œäº†ï¼Kaggleã§ã®çµæœã‚’ãŠæ¥½ã—ã¿ã«ï¼\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}