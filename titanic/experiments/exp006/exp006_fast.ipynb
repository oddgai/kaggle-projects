{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp006 - ã€ŒLess is Moreã€ã«ã‚ˆã‚‹ç²¾å¯†æœ€é©åŒ–ï¼ˆé«˜é€Ÿç‰ˆï¼‰\n",
    "\n",
    "exp005ã®å¤±æ•—ã‚’å—ã‘ã¦ã€ã‚·ãƒ³ãƒ—ãƒ«åŒ–ã¨åŠ¹ç‡çš„ãªæœ€é©åŒ–ã«ã‚ˆã‚‹æ”¹å–„ã‚’ç›®æŒ‡ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "\n",
    "print(\"ğŸ¯ exp006 - Less is Moreæˆ¦ç•¥ï¼ˆé«˜é€Ÿç‰ˆï¼‰\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "train_df = pd.read_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/data/train.csv')\n",
    "test_df = pd.read_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp004ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆç°¡ç•¥ç‰ˆï¼‰\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # åå‰ã‹ã‚‰ã®ç‰¹å¾´é‡\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
    "        'Mlle': 'Miss', 'Countess': 'Rare', 'Ms': 'Mrs', 'Lady': 'Rare',\n",
    "        'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Mrs',\n",
    "        'Capt': 'Rare', 'Sir': 'Rare'\n",
    "    }\n",
    "    df['Title_Grouped'] = df['Title'].map(title_mapping).fillna('Other')\n",
    "    \n",
    "    # è‹—å­—ã¨å®¶æ—ã‚µã‚¤ã‚º\n",
    "    df['Surname'] = df['Name'].str.split(',').str[0]\n",
    "    all_surnames = pd.concat([train_df['Name'], test_df['Name']]).str.split(',').str[0]\n",
    "    surname_counts = all_surnames.value_counts()\n",
    "    df['Surname_Count'] = df['Surname'].map(surname_counts)\n",
    "    \n",
    "    # ãƒã‚±ãƒƒãƒˆãƒ»å®¢å®¤ç‰¹å¾´é‡\n",
    "    df['Ticket_IsNumeric'] = df['Ticket'].str.isnumeric().astype(int)\n",
    "    all_tickets = pd.concat([train_df['Ticket'], test_df['Ticket']])\n",
    "    ticket_counts = all_tickets.value_counts()\n",
    "    df['Ticket_Count'] = df['Ticket'].map(ticket_counts)\n",
    "    \n",
    "    df['HasCabin'] = (~df['Cabin'].isnull()).astype(int)\n",
    "    \n",
    "    # åŸºæœ¬å‰å‡¦ç†\n",
    "    df['Sex_Binary'] = df['Sex'].map({'female': 0, 'male': 1})\n",
    "    df['Age'] = df.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    # å®¶æ—æ§‹æˆ\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # äº¤äº’ä½œç”¨\n",
    "    df['Sex_Pclass'] = df['Sex_Binary'] * df['Pclass']\n",
    "    df['Age_Fare_Interaction'] = df['Age'] * df['Fare']\n",
    "    \n",
    "    # çµ±è¨ˆç‰¹å¾´é‡\n",
    "    df['Age_Rank_SexPclass'] = df.groupby(['Sex_Binary', 'Pclass'])['Age'].rank(pct=True)\n",
    "    df['Fare_Rank_Pclass'] = df.groupby('Pclass')['Fare'].rank(pct=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ç‰¹å¾´é‡ä½œæˆ\n",
    "train_processed = create_features(train_df)\n",
    "test_processed = create_features(test_df)\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "for feature in ['Embarked', 'Title_Grouped']:\n",
    "    le = LabelEncoder()\n",
    "    all_categories = pd.concat([train_processed[feature], test_processed[feature]]).astype(str)\n",
    "    le.fit(all_categories)\n",
    "    \n",
    "    train_processed[feature] = le.transform(train_processed[feature].astype(str))\n",
    "    test_processed[feature] = le.transform(test_processed[feature].astype(str))\n",
    "\n",
    "print(\"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é‡è¦åº¦ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡é¸æŠ\n",
    "exclude_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived', 'Surname', 'Title', 'Sex']\n",
    "candidate_features = [col for col in train_processed.columns \n",
    "                     if col not in exclude_features and \n",
    "                     train_processed[col].dtype in ['int64', 'float64', 'int32', 'float32']]\n",
    "\n",
    "X_full = train_processed[candidate_features]\n",
    "y = train_processed['Survived']\n",
    "X_test_full = test_processed[candidate_features]\n",
    "\n",
    "print(f\"å€™è£œç‰¹å¾´é‡: {len(candidate_features)}å€‹\")\n",
    "\n",
    "# é‡è¦åº¦å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰\n",
    "lgb_simple = lgb.LGBMClassifier(random_state=42, verbose=-1, n_estimators=100)\n",
    "lgb_simple.fit(X_full, y)\n",
    "importance_scores = lgb_simple.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': candidate_features,\n",
    "    'importance': importance_scores\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\né‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°:\")\n",
    "for i, row in importance_df.head(15).iterrows():\n",
    "    print(f\"{importance_df.index.get_loc(i)+1:2d}. {row['feature']:20s}: {row['importance']:8.4f}\")\n",
    "\n",
    "# æœ€é©ç‰¹å¾´é‡ã‚»ãƒƒãƒˆæ±ºå®šï¼ˆé‡è¦åº¦ä¸Šä½15å€‹ï¼‰\n",
    "optimal_features = importance_df.head(15)['feature'].tolist()\n",
    "print(f\"\\né¸æŠç‰¹å¾´é‡: {len(optimal_features)}å€‹\")\n",
    "\n",
    "X_optimal = X_full[optimal_features]\n",
    "X_test_optimal = X_test_full[optimal_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è»½é‡Optunaæœ€é©åŒ–\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 200,  # é«˜é€ŸåŒ–ã®ãŸã‚å‰Šæ¸›\n",
    "        \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.15),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0)\n",
    "    }\n",
    "    \n",
    "    # 3-fold CVï¼ˆé«˜é€ŸåŒ–ï¼‰\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_optimal, y):\n",
    "        X_train, X_val = X_optimal.iloc[train_idx], X_optimal.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                 callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])\n",
    "        \n",
    "        val_pred = model.predict(X_val)\n",
    "        fold_score = accuracy_score(y_val, val_pred)\n",
    "        cv_scores.append(fold_score)\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "print(\"\\nOptunaæœ€é©åŒ–é–‹å§‹ï¼ˆ30å›è©¦è¡Œï¼‰...\")\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\næœ€é«˜CVç²¾åº¦: {study.best_value:.4f}\")\n",
    "print(\"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"{param:20s}: {value}\")\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\n",
    "print(\"\\næœ€çµ‚ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ä¸­...\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "final_cv_scores = []\n",
    "oof_predictions = np.zeros(len(X_optimal))\n",
    "test_predictions = np.zeros(len(X_test_optimal))\n",
    "feature_importance_final = np.zeros(len(optimal_features))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_optimal, y), 1):\n",
    "    X_train, X_val = X_optimal.iloc[train_idx], X_optimal.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**best_params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "             callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)])\n",
    "    \n",
    "    # äºˆæ¸¬\n",
    "    val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    val_pred = model.predict(X_val)\n",
    "    test_pred_proba = model.predict_proba(X_test_optimal)[:, 1]\n",
    "    \n",
    "    fold_score = accuracy_score(y_val, val_pred)\n",
    "    final_cv_scores.append(fold_score)\n",
    "    \n",
    "    oof_predictions[val_idx] = val_pred_proba\n",
    "    test_predictions += test_pred_proba / 5\n",
    "    feature_importance_final += model.feature_importances_\n",
    "    \n",
    "    print(f\"Fold {fold}: {fold_score:.4f}\")\n",
    "\n",
    "final_cv_mean = np.mean(final_cv_scores)\n",
    "final_cv_std = np.std(final_cv_scores)\n",
    "oof_accuracy = accuracy_score(y, (oof_predictions >= 0.5).astype(int))\n",
    "feature_importance_final /= 5\n",
    "\n",
    "print(f\"\\n=== æœ€çµ‚çµæœ ===\")\n",
    "print(f\"CV Accuracy: {final_cv_mean:.4f} Â± {final_cv_std:.4f}\")\n",
    "print(f\"OOF Accuracy: {oof_accuracy:.4f}\")\n",
    "\n",
    "# exp004ã¨ã®æ¯”è¼ƒ\n",
    "exp004_cv = 0.8462\n",
    "exp004_kaggle = 0.77990\n",
    "cv_improvement = final_cv_mean - exp004_cv\n",
    "expected_kaggle = final_cv_mean * (exp004_kaggle / exp004_cv)\n",
    "kaggle_improvement = expected_kaggle - exp004_kaggle\n",
    "\n",
    "print(f\"\\n=== exp004ã¨ã®æ¯”è¼ƒ ===\")\n",
    "print(f\"exp004 CV: {exp004_cv:.4f}\")\n",
    "print(f\"exp006 CV: {final_cv_mean:.4f} ({cv_improvement:+.4f})\")\n",
    "print(f\"\\næœŸå¾…Kaggle: {expected_kaggle:.5f}\")\n",
    "print(f\"exp004ã‹ã‚‰: {kaggle_improvement:+.5f} ({kaggle_improvement/exp004_kaggle*100:+.2f}%)\")\n",
    "\n",
    "if kaggle_improvement > 0.005:\n",
    "    print(\"ğŸ‰ å¤§å¹…æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã‚‹ï¼\")\n",
    "elif kaggle_improvement > 0:\n",
    "    print(\"âœ… æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã‚‹\")\n",
    "else:\n",
    "    print(\"âš ï¸ æ”¹å–„ã¯é™å®šçš„\")\n",
    "\n",
    "# æœ€çµ‚ç‰¹å¾´é‡é‡è¦åº¦\n",
    "final_importance_df = pd.DataFrame({\n",
    "    'feature': optimal_features,\n",
    "    'importance': feature_importance_final\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\n=== æœ€çµ‚ç‰¹å¾´é‡é‡è¦åº¦ ===\")\n",
    "for i, row in final_importance_df.iterrows():\n",
    "    print(f\"{final_importance_df.index.get_loc(i)+1:2d}. {row['feature']:20s}: {row['importance']:8.4f}\")\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(final_importance_df)), final_importance_df['importance'])\n",
    "plt.yticks(range(len(final_importance_df)), final_importance_df['feature'])\n",
    "plt.xlabel('é‡è¦åº¦')\n",
    "plt.title(f'exp006æœ€çµ‚ç‰¹å¾´é‡é‡è¦åº¦ ({len(optimal_features)}ç‰¹å¾´é‡)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ\n",
    "test_predictions_binary = (test_predictions >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_processed['PassengerId'],\n",
    "    'Survived': test_predictions_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/results/exp006/result.csv', index=False)\n",
    "\n",
    "print(f\"\\n=== æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº† ===\")\n",
    "print(f\"ç”Ÿå­˜äºˆæ¸¬æ•°: {test_predictions_binary.sum()}\")\n",
    "print(f\"æ­»äº¡äºˆæ¸¬æ•°: {len(test_predictions_binary) - test_predictions_binary.sum()}\")\n",
    "print(f\"äºˆæ¸¬ç”Ÿå­˜ç‡: {test_predictions_binary.mean():.3f}\")\n",
    "print(f\"å®Ÿéš›ç”Ÿå­˜ç‡: {y.mean():.3f}\")\n",
    "print(f\"\\nğŸ’¾ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: results/exp006/result.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"                ğŸ¯ EXP006 å®Œäº†\")\n",
    "print(\"=\"*60)\n",
    "print(f\"æˆ¦ç•¥: Less is Moreï¼ˆ{len(optimal_features)}ç‰¹å¾´é‡ï¼‰\")\n",
    "print(f\"CVæ€§èƒ½: {final_cv_mean:.4f} Â± {final_cv_std:.4f}\")\n",
    "print(f\"æœŸå¾…æ”¹å–„: {kaggle_improvement:+.5f}\")\n",
    "print(\"Kaggleã§ã®çµæœã‚’ãŠæ¥½ã—ã¿ã«ï¼\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}