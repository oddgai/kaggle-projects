{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp006 - 「Less is More」による精密最適化（高速版）\n",
    "\n",
    "exp005の失敗を受けて、シンプル化と効率的な最適化による改善を目指す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "\n",
    "print(\"🎯 exp006 - Less is More戦略（高速版）\")\n",
    "\n",
    "# データ読み込み\n",
    "train_df = pd.read_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/data/train.csv')\n",
    "test_df = pd.read_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp004特徴量エンジニアリング（簡略版）\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 名前からの特徴量\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.')\n",
    "    title_mapping = {\n",
    "        'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', 'Master': 'Master',\n",
    "        'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
    "        'Mlle': 'Miss', 'Countess': 'Rare', 'Ms': 'Mrs', 'Lady': 'Rare',\n",
    "        'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Mrs',\n",
    "        'Capt': 'Rare', 'Sir': 'Rare'\n",
    "    }\n",
    "    df['Title_Grouped'] = df['Title'].map(title_mapping).fillna('Other')\n",
    "    \n",
    "    # 苗字と家族サイズ\n",
    "    df['Surname'] = df['Name'].str.split(',').str[0]\n",
    "    all_surnames = pd.concat([train_df['Name'], test_df['Name']]).str.split(',').str[0]\n",
    "    surname_counts = all_surnames.value_counts()\n",
    "    df['Surname_Count'] = df['Surname'].map(surname_counts)\n",
    "    \n",
    "    # チケット・客室特徴量\n",
    "    df['Ticket_IsNumeric'] = df['Ticket'].str.isnumeric().astype(int)\n",
    "    all_tickets = pd.concat([train_df['Ticket'], test_df['Ticket']])\n",
    "    ticket_counts = all_tickets.value_counts()\n",
    "    df['Ticket_Count'] = df['Ticket'].map(ticket_counts)\n",
    "    \n",
    "    df['HasCabin'] = (~df['Cabin'].isnull()).astype(int)\n",
    "    \n",
    "    # 基本前処理\n",
    "    df['Sex_Binary'] = df['Sex'].map({'female': 0, 'male': 1})\n",
    "    df['Age'] = df.groupby(['Sex', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Fare'] = df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    # 家族構成\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 交互作用\n",
    "    df['Sex_Pclass'] = df['Sex_Binary'] * df['Pclass']\n",
    "    df['Age_Fare_Interaction'] = df['Age'] * df['Fare']\n",
    "    \n",
    "    # 統計特徴量\n",
    "    df['Age_Rank_SexPclass'] = df.groupby(['Sex_Binary', 'Pclass'])['Age'].rank(pct=True)\n",
    "    df['Fare_Rank_Pclass'] = df.groupby('Pclass')['Fare'].rank(pct=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 特徴量作成\n",
    "train_processed = create_features(train_df)\n",
    "test_processed = create_features(test_df)\n",
    "\n",
    "# カテゴリカルエンコーディング\n",
    "for feature in ['Embarked', 'Title_Grouped']:\n",
    "    le = LabelEncoder()\n",
    "    all_categories = pd.concat([train_processed[feature], test_processed[feature]]).astype(str)\n",
    "    le.fit(all_categories)\n",
    "    \n",
    "    train_processed[feature] = le.transform(train_processed[feature].astype(str))\n",
    "    test_processed[feature] = le.transform(test_processed[feature].astype(str))\n",
    "\n",
    "print(\"特徴量エンジニアリング完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重要度ベース特徴量選択\n",
    "exclude_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived', 'Surname', 'Title', 'Sex']\n",
    "candidate_features = [col for col in train_processed.columns \n",
    "                     if col not in exclude_features and \n",
    "                     train_processed[col].dtype in ['int64', 'float64', 'int32', 'float32']]\n",
    "\n",
    "X_full = train_processed[candidate_features]\n",
    "y = train_processed['Survived']\n",
    "X_test_full = test_processed[candidate_features]\n",
    "\n",
    "print(f\"候補特徴量: {len(candidate_features)}個\")\n",
    "\n",
    "# 重要度取得（簡易版）\n",
    "lgb_simple = lgb.LGBMClassifier(random_state=42, verbose=-1, n_estimators=100)\n",
    "lgb_simple.fit(X_full, y)\n",
    "importance_scores = lgb_simple.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': candidate_features,\n",
    "    'importance': importance_scores\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n重要度ランキング:\")\n",
    "for i, row in importance_df.head(15).iterrows():\n",
    "    print(f\"{importance_df.index.get_loc(i)+1:2d}. {row['feature']:20s}: {row['importance']:8.4f}\")\n",
    "\n",
    "# 最適特徴量セット決定（重要度上位15個）\n",
    "optimal_features = importance_df.head(15)['feature'].tolist()\n",
    "print(f\"\\n選択特徴量: {len(optimal_features)}個\")\n",
    "\n",
    "X_optimal = X_full[optimal_features]\n",
    "X_test_optimal = X_test_full[optimal_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 軽量Optuna最適化\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 200,  # 高速化のため削減\n",
    "        \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.15),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0)\n",
    "    }\n",
    "    \n",
    "    # 3-fold CV（高速化）\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_optimal, y):\n",
    "        X_train, X_val = X_optimal.iloc[train_idx], X_optimal.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                 callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])\n",
    "        \n",
    "        val_pred = model.predict(X_val)\n",
    "        fold_score = accuracy_score(y_val, val_pred)\n",
    "        cv_scores.append(fold_score)\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "print(\"\\nOptuna最適化開始（30回試行）...\")\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n最高CV精度: {study.best_value:.4f}\")\n",
    "print(\"最適パラメータ:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"{param:20s}: {value}\")\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終モデル構築\n",
    "print(\"\\n最終モデル構築中...\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "final_cv_scores = []\n",
    "oof_predictions = np.zeros(len(X_optimal))\n",
    "test_predictions = np.zeros(len(X_test_optimal))\n",
    "feature_importance_final = np.zeros(len(optimal_features))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_optimal, y), 1):\n",
    "    X_train, X_val = X_optimal.iloc[train_idx], X_optimal.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**best_params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "             callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)])\n",
    "    \n",
    "    # 予測\n",
    "    val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    val_pred = model.predict(X_val)\n",
    "    test_pred_proba = model.predict_proba(X_test_optimal)[:, 1]\n",
    "    \n",
    "    fold_score = accuracy_score(y_val, val_pred)\n",
    "    final_cv_scores.append(fold_score)\n",
    "    \n",
    "    oof_predictions[val_idx] = val_pred_proba\n",
    "    test_predictions += test_pred_proba / 5\n",
    "    feature_importance_final += model.feature_importances_\n",
    "    \n",
    "    print(f\"Fold {fold}: {fold_score:.4f}\")\n",
    "\n",
    "final_cv_mean = np.mean(final_cv_scores)\n",
    "final_cv_std = np.std(final_cv_scores)\n",
    "oof_accuracy = accuracy_score(y, (oof_predictions >= 0.5).astype(int))\n",
    "feature_importance_final /= 5\n",
    "\n",
    "print(f\"\\n=== 最終結果 ===\")\n",
    "print(f\"CV Accuracy: {final_cv_mean:.4f} ± {final_cv_std:.4f}\")\n",
    "print(f\"OOF Accuracy: {oof_accuracy:.4f}\")\n",
    "\n",
    "# exp004との比較\n",
    "exp004_cv = 0.8462\n",
    "exp004_kaggle = 0.77990\n",
    "cv_improvement = final_cv_mean - exp004_cv\n",
    "expected_kaggle = final_cv_mean * (exp004_kaggle / exp004_cv)\n",
    "kaggle_improvement = expected_kaggle - exp004_kaggle\n",
    "\n",
    "print(f\"\\n=== exp004との比較 ===\")\n",
    "print(f\"exp004 CV: {exp004_cv:.4f}\")\n",
    "print(f\"exp006 CV: {final_cv_mean:.4f} ({cv_improvement:+.4f})\")\n",
    "print(f\"\\n期待Kaggle: {expected_kaggle:.5f}\")\n",
    "print(f\"exp004から: {kaggle_improvement:+.5f} ({kaggle_improvement/exp004_kaggle*100:+.2f}%)\")\n",
    "\n",
    "if kaggle_improvement > 0.005:\n",
    "    print(\"🎉 大幅改善が期待される！\")\n",
    "elif kaggle_improvement > 0:\n",
    "    print(\"✅ 改善が期待される\")\n",
    "else:\n",
    "    print(\"⚠️ 改善は限定的\")\n",
    "\n",
    "# 最終特徴量重要度\n",
    "final_importance_df = pd.DataFrame({\n",
    "    'feature': optimal_features,\n",
    "    'importance': feature_importance_final\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\n=== 最終特徴量重要度 ===\")\n",
    "for i, row in final_importance_df.iterrows():\n",
    "    print(f\"{final_importance_df.index.get_loc(i)+1:2d}. {row['feature']:20s}: {row['importance']:8.4f}\")\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(final_importance_df)), final_importance_df['importance'])\n",
    "plt.yticks(range(len(final_importance_df)), final_importance_df['feature'])\n",
    "plt.xlabel('重要度')\n",
    "plt.title(f'exp006最終特徴量重要度 ({len(optimal_features)}特徴量)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイル生成\n",
    "test_predictions_binary = (test_predictions >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_processed['PassengerId'],\n",
    "    'Survived': test_predictions_binary\n",
    "})\n",
    "\n",
    "submission.to_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/results/exp006/result.csv', index=False)\n",
    "\n",
    "print(f\"\\n=== 提出ファイル生成完了 ===\")\n",
    "print(f\"生存予測数: {test_predictions_binary.sum()}\")\n",
    "print(f\"死亡予測数: {len(test_predictions_binary) - test_predictions_binary.sum()}\")\n",
    "print(f\"予測生存率: {test_predictions_binary.mean():.3f}\")\n",
    "print(f\"実際生存率: {y.mean():.3f}\")\n",
    "print(f\"\\n💾 提出ファイル保存: results/exp006/result.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"                🎯 EXP006 完了\")\n",
    "print(\"=\"*60)\n",
    "print(f\"戦略: Less is More（{len(optimal_features)}特徴量）\")\n",
    "print(f\"CV性能: {final_cv_mean:.4f} ± {final_cv_std:.4f}\")\n",
    "print(f\"期待改善: {kaggle_improvement:+.5f}\")\n",
    "print(\"Kaggleでの結果をお楽しみに！\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}