# exp003 - 特徴量選択による改善試行

## 概要

exp001の特徴量重要度を基に、上位7特徴量のみを使用してモデルの精度向上を目指した実験。

## ベースとなる実験

exp001（LightGBMベースライン、16特徴量）

## 実験設定

### 使用モデル

LightGBM（回帰モード + 閾値0.5での二値分類）

### 特徴量

exp001の特徴量重要度上位7特徴量を選択：

1. **Sex_Pclass** (重要度: 1556.6) - 性別×客室クラスの交互作用特徴量
2. **Sex** (重要度: 766.6) - 性別（0: female, 1: male）
3. **Age** (重要度: 550.5) - 年齢（欠損値は中央値で補完）
4. **Fare** (重要度: 444.1) - 運賃
5. **HasCabin** (重要度: 419.7) - 客室情報有無フラグ
6. **Pclass** (重要度: 406.2) - 客室クラス（1, 2, 3）
7. **Embarked** (重要度: 183.7) - 乗船港（C, Q, Sエンコード）

### モデルパラメータ

```python
lgb_params = {
    'objective': 'regression',
    'metric': 'rmse',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.1,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': -1,
    'random_state': 42
}
```

### 検証方法

5-fold StratifiedKFold交差検証

## 結果

### 性能指標

- **Kaggleスコア**: 0.76315
- **検証データ精度**: 0.8156
- **CV精度**: 0.8316 ± 0.041

### 特徴量重要度（exp003）

| 順位 | 特徴量 | 重要度 |
|------|--------|--------|
| 1 | Sex_Pclass | 1610.4 |
| 2 | Sex | 816.2 |
| 3 | Age | 601.5 |
| 4 | Fare | 476.3 |
| 5 | HasCabin | 446.8 |
| 6 | Pclass | 425.1 |
| 7 | Embarked | 194.7 |

## 分析

### 実験結果の考察

1. **精度の変化**
   - Kaggleスコア: 0.77272 → 0.76315 (▼0.00957)
   - CVスコア: 0.8496±0.026 → 0.8316±0.041 (▼0.018)
   - **結論**: 特徴量を16個から7個に削減したことで精度が低下した

2. **特徴量選択の効果**
   - 重要度下位9特徴量を除外したが、これらの特徴量も予測に一定の貢献をしていた
   - 単純な特徴量削減では情報損失により性能が悪化することが判明

3. **CV分散の増加**
   - 標準偏差が0.026から0.041に増加（約1.6倍）
   - 特徴量数の減少により、モデルの安定性が低下

### 次の実験に向けた改善案

1. **高度な特徴量エンジニアリング**
   - より複雑な特徴量の組み合わせや変換を試行
   - 多項式特徴量やビニング戦略の見直し

2. **アンサンブル手法の導入**
   - 異なるアルゴリズム（RandomForest、XGBoost等）との組み合わせ
   - Stacking・Blendingによる予測精度向上

3. **ハイパーパラメータ最適化**
   - Bayesian OptimizationやOptunaを使用した組み合わせ最適化
   - Early Stoppingパラメータの調整

4. **外れ値処理とデータクリーニング**
   - 運賃や年齢の外れ値に対するより詳細な分析
   - 欠損値補完手法の改善（KNN補完等）

## 結論

特徴量選択による単純な次元削減では精度向上は達成できなかった。exp001の16特徴量全てが予測に寄与していることが判明。今後は特徴量の質的向上やアンサンブル手法による改善を検討する必要がある。