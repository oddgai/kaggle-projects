{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp008 - Advanced Feature Engineering (Kaggleチュートリアル参考)\n",
    "\n",
    "## 🎯 目標\n",
    "- 高度な特徴量エンジニアリング手法の実装\n",
    "- Title、Cabin、Ticket、Familyの詳細分析\n",
    "- exp004（0.77990）を超える性能を目指す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import re\n",
    "\n",
    "plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "\n",
    "print(\"🚀 exp008 - Advanced Feature Engineering\")\n",
    "print(\"Kaggleチュートリアルの手法を参考に実装\")\n",
    "\n",
    "# データ読み込み\n",
    "train_df = pd.read_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/data/train.csv')\n",
    "test_df = pd.read_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/data/test.csv')\n",
    "\n",
    "# データ結合（前処理の一貫性のため）\n",
    "df_all = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
    "df_all['is_train'] = df_all['Survived'].notna()\n",
    "\n",
    "print(f\"\\n全データ shape: {df_all.shape}\")\n",
    "print(f\"訓練データ: {df_all['is_train'].sum()}件\")\n",
    "print(f\"テストデータ: {(~df_all['is_train']).sum()}件\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Phase 1: Title（称号）の高度な処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Titleの抽出と詳細分析\n",
    "df_all['Title'] = df_all['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "print(\"=== Title分布 ===\")\n",
    "print(df_all['Title'].value_counts())\n",
    "\n",
    "# Title別の生存率（訓練データのみ）\n",
    "title_survival = df_all[df_all['is_train']].groupby('Title')['Survived'].agg(['mean', 'count']).round(3)\n",
    "print(\"\\n=== Title別生存率 ===\")\n",
    "print(title_survival.sort_values('mean', ascending=False))\n",
    "\n",
    "# Titleのマッピング（より詳細な分類）\n",
    "title_mapping = {\n",
    "    # 一般的な称号\n",
    "    'Mr': 'Mr',\n",
    "    'Miss': 'Miss',\n",
    "    'Mrs': 'Mrs',\n",
    "    'Master': 'Master',\n",
    "    \n",
    "    # フランス語の称号\n",
    "    'Mlle': 'Miss',  # Mademoiselle\n",
    "    'Mme': 'Mrs',    # Madame\n",
    "    'Ms': 'Miss',\n",
    "    \n",
    "    # 軍人\n",
    "    'Col': 'Officer',\n",
    "    'Major': 'Officer',\n",
    "    'Capt': 'Officer',\n",
    "    \n",
    "    # 貴族\n",
    "    'Lady': 'Royalty',\n",
    "    'Sir': 'Royalty',\n",
    "    'Countess': 'Royalty',\n",
    "    'Don': 'Royalty',\n",
    "    'Dona': 'Royalty',\n",
    "    'Jonkheer': 'Royalty',\n",
    "    \n",
    "    # 聖職者・専門職\n",
    "    'Dr': 'Dr',\n",
    "    'Rev': 'Rev'\n",
    "}\n",
    "\n",
    "df_all['Title_Grouped'] = df_all['Title'].map(title_mapping)\n",
    "\n",
    "# 年齢とTitleの組み合わせで詳細化\n",
    "df_all['Is_Child'] = ((df_all['Title'] == 'Master') | \n",
    "                      ((df_all['Title'] == 'Miss') & (df_all['Age'] < 18))).astype(int)\n",
    "\n",
    "df_all['Is_Young_Miss'] = ((df_all['Title'] == 'Miss') & \n",
    "                           (df_all['Age'] >= 18) & (df_all['Age'] < 30)).astype(int)\n",
    "\n",
    "df_all['Is_Mrs'] = (df_all['Title'] == 'Mrs').astype(int)\n",
    "\n",
    "print(\"\\n=== Title特徴量作成完了 ===\")\n",
    "print(f\"Title_Grouped分布:\")\n",
    "print(df_all['Title_Grouped'].value_counts())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏠 Phase 2: Cabin（客室）の詳細処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cabin情報の詳細抽出\n",
    "df_all['Has_Cabin'] = df_all['Cabin'].notna().astype(int)\n",
    "\n",
    "# デッキの抽出\n",
    "df_all['Deck'] = df_all['Cabin'].str[0]\n",
    "\n",
    "# 複数客室を持つ乗客の処理\n",
    "df_all['Cabin_Count'] = df_all['Cabin'].str.split().str.len()\n",
    "df_all['Cabin_Count'] = df_all['Cabin_Count'].fillna(0)\n",
    "\n",
    "# デッキによるスコアリング（救命ボートへの近さ）\n",
    "deck_mapping = {\n",
    "    'A': 7, 'B': 6, 'C': 5, 'D': 4,\n",
    "    'E': 3, 'F': 2, 'G': 1, 'T': 0\n",
    "}\n",
    "df_all['Deck_Num'] = df_all['Deck'].map(deck_mapping)\n",
    "\n",
    "# Pclassとデッキの相関を利用した欠損値補完\n",
    "for pclass in [1, 2, 3]:\n",
    "    deck_mode = df_all[(df_all['Pclass'] == pclass) & df_all['Deck'].notna()]['Deck'].mode()\n",
    "    if len(deck_mode) > 0:\n",
    "        df_all.loc[(df_all['Pclass'] == pclass) & df_all['Deck'].isna(), 'Deck'] = deck_mode[0]\n",
    "\n",
    "# デッキが不明な場合はPclassベースで推定\n",
    "df_all['Deck'] = df_all['Deck'].fillna('U')  # Unknown\n",
    "df_all['Deck_Num'] = df_all['Deck_Num'].fillna(-1)\n",
    "\n",
    "# 客室番号から位置を推定（数値部分）\n",
    "def extract_cabin_number(cabin):\n",
    "    if pd.isna(cabin):\n",
    "        return -1\n",
    "    numbers = re.findall(r'\\d+', str(cabin))\n",
    "    if numbers:\n",
    "        return int(numbers[0])\n",
    "    return -1\n",
    "\n",
    "df_all['Cabin_Number'] = df_all['Cabin'].apply(extract_cabin_number)\n",
    "\n",
    "# 客室位置スコア（前方/中央/後方）\n",
    "df_all['Cabin_Position'] = pd.cut(df_all['Cabin_Number'], \n",
    "                                   bins=[-2, 0, 50, 100, 200],\n",
    "                                   labels=['Unknown', 'Front', 'Middle', 'Back'])\n",
    "\n",
    "print(\"=== Cabin特徴量作成完了 ===\")\n",
    "print(f\"\\nデッキ分布:\")\n",
    "print(df_all['Deck'].value_counts())\n",
    "print(f\"\\n複数客室保有者: {(df_all['Cabin_Count'] > 1).sum()}人\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎫 Phase 3: Ticket（チケット）の詳細分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# チケット番号の前処理\n",
    "df_all['Ticket_Cleaned'] = df_all['Ticket'].str.replace('[^A-Za-z0-9]', '', regex=True)\n",
    "\n",
    "# チケットプレフィックスの抽出\n",
    "df_all['Ticket_Prefix'] = df_all['Ticket'].str.extract(r'([A-Za-z\\.]+)', expand=False)\n",
    "df_all['Ticket_Prefix'] = df_all['Ticket_Prefix'].str.replace('[^A-Za-z]', '', regex=True)\n",
    "df_all['Ticket_Prefix'] = df_all['Ticket_Prefix'].fillna('NONE')\n",
    "\n",
    "# チケット番号（数値部分）の抽出\n",
    "df_all['Ticket_Number'] = df_all['Ticket'].str.extract(r'(\\d+)', expand=False)\n",
    "df_all['Ticket_Number'] = pd.to_numeric(df_all['Ticket_Number'], errors='coerce')\n",
    "\n",
    "# チケットグループサイズ（同じチケット番号を持つ人数）\n",
    "ticket_counts = df_all['Ticket'].value_counts()\n",
    "df_all['Ticket_Group_Size'] = df_all['Ticket'].map(ticket_counts)\n",
    "\n",
    "# 連番チケットの識別（家族や団体の可能性）\n",
    "df_all['Ticket_Number_Sorted'] = df_all.groupby('Ticket_Prefix')['Ticket_Number'].rank(method='dense')\n",
    "\n",
    "# チケット価格の正規化（グループサイズで割る）\n",
    "df_all['Fare_Per_Person'] = df_all['Fare'] / df_all['Ticket_Group_Size']\n",
    "\n",
    "# チケットプレフィックス別の統計\n",
    "prefix_stats = df_all[df_all['is_train']].groupby('Ticket_Prefix')['Survived'].agg(['mean', 'count'])\n",
    "prefix_stats = prefix_stats[prefix_stats['count'] >= 5]  # 5件以上のプレフィックスのみ\n",
    "\n",
    "print(\"=== 主要チケットプレフィックス別生存率 ===\")\n",
    "print(prefix_stats.sort_values('mean', ascending=False).head(10))\n",
    "\n",
    "# 希少プレフィックスの統合\n",
    "frequent_prefixes = prefix_stats[prefix_stats['count'] >= 10].index.tolist()\n",
    "df_all['Ticket_Prefix_Grouped'] = df_all['Ticket_Prefix'].apply(\n",
    "    lambda x: x if x in frequent_prefixes else 'OTHER'\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Ticket特徴量作成完了 ===\")\n",
    "print(f\"グループチケット: {(df_all['Ticket_Group_Size'] > 1).sum()}件\")\n",
    "print(f\"一人あたり運賃中央値: ${df_all['Fare_Per_Person'].median():.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👨‍👩‍👧‍👦 Phase 4: Family（家族）の複雑な関係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 基本的な家族サイズ\n",
    "df_all['FamilySize'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "df_all['IsAlone'] = (df_all['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# 家族サイズのカテゴリ化\n",
    "df_all['FamilySize_Cat'] = pd.cut(df_all['FamilySize'], \n",
    "                                   bins=[0, 1, 3, 5, 20],\n",
    "                                   labels=['Alone', 'Small', 'Medium', 'Large'])\n",
    "\n",
    "# 苗字の抽出\n",
    "df_all['Surname'] = df_all['Name'].str.split(',').str[0]\n",
    "\n",
    "# 同一苗字グループのサイズ\n",
    "surname_counts = df_all['Surname'].value_counts()\n",
    "df_all['Surname_Count'] = df_all['Surname'].map(surname_counts)\n",
    "\n",
    "# 女性と子供を持つ男性の識別（家族の保護者）\n",
    "df_all['Is_Mother'] = ((df_all['Sex'] == 'female') & \n",
    "                       (df_all['Parch'] > 0) & \n",
    "                       (df_all['Age'] > 18)).astype(int)\n",
    "\n",
    "df_all['Is_Father'] = ((df_all['Sex'] == 'male') & \n",
    "                       (df_all['Parch'] > 0) & \n",
    "                       (df_all['Age'] > 18)).astype(int)\n",
    "\n",
    "# 家族タイプの詳細分類\n",
    "def classify_family_type(row):\n",
    "    if row['IsAlone']:\n",
    "        return 'Alone'\n",
    "    elif row['Is_Mother']:\n",
    "        return 'Mother'\n",
    "    elif row['Is_Father']:\n",
    "        return 'Father'\n",
    "    elif row['Is_Child']:\n",
    "        return 'Child'\n",
    "    elif row['SibSp'] > 0 and row['Parch'] == 0:\n",
    "        return 'Sibling'\n",
    "    elif row['SibSp'] == 0 and row['Parch'] > 0:\n",
    "        return 'Parent_Child'\n",
    "    else:\n",
    "        return 'Extended'\n",
    "\n",
    "df_all['Family_Type'] = df_all.apply(classify_family_type, axis=1)\n",
    "\n",
    "# 同一苗字・チケットグループの生存率（訓練データから計算）\n",
    "train_data = df_all[df_all['is_train']].copy()\n",
    "\n",
    "# 苗字別生存率\n",
    "surname_survival = train_data.groupby('Surname')['Survived'].agg(['mean', 'count'])\n",
    "surname_survival.columns = ['Surname_Survival_Rate', 'Surname_Group_Count']\n",
    "df_all = df_all.merge(surname_survival, on='Surname', how='left')\n",
    "\n",
    "# 少人数苗字の生存率は全体平均で補完\n",
    "overall_survival_rate = train_data['Survived'].mean()\n",
    "df_all.loc[df_all['Surname_Group_Count'] < 3, 'Surname_Survival_Rate'] = overall_survival_rate\n",
    "\n",
    "print(\"=== Family Type分布 ===\")\n",
    "print(df_all['Family_Type'].value_counts())\n",
    "\n",
    "# Family Type別生存率（訓練データ）\n",
    "family_survival = train_data.groupby('Family_Type')['Survived'].mean().round(3)\n",
    "print(\"\\n=== Family Type別生存率 ===\")\n",
    "print(family_survival.sort_values(ascending=False))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Phase 5: 欠損値の高度な補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Age（年齢）の欠損値補完\n",
    "# Title、Pclass、Sex、Fareを使った予測\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 年齢予測用の特徴量\n",
    "age_features = ['Pclass', 'SibSp', 'Parch', 'Fare_Per_Person']\n",
    "\n",
    "# カテゴリカル変数のエンコード（年齢予測用）\n",
    "le_sex = LabelEncoder()\n",
    "df_all['Sex_Encoded'] = le_sex.fit_transform(df_all['Sex'])\n",
    "age_features.append('Sex_Encoded')\n",
    "\n",
    "le_title = LabelEncoder()\n",
    "df_all['Title_Encoded'] = le_title.fit_transform(df_all['Title_Grouped'].fillna('Unknown'))\n",
    "age_features.append('Title_Encoded')\n",
    "\n",
    "# 年齢予測モデル\n",
    "age_train = df_all[df_all['Age'].notna()][age_features + ['Age']].copy()\n",
    "age_test = df_all[df_all['Age'].isna()][age_features].copy()\n",
    "\n",
    "# 欠損値処理\n",
    "age_train = age_train.fillna(age_train.median())\n",
    "age_test = age_test.fillna(age_train.median())\n",
    "\n",
    "if len(age_test) > 0:\n",
    "    rf_age = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_age.fit(age_train[age_features], age_train['Age'])\n",
    "    predicted_ages = rf_age.predict(age_test[age_features])\n",
    "    df_all.loc[df_all['Age'].isna(), 'Age'] = predicted_ages\n",
    "    print(f\"年齢を{len(age_test)}件予測補完\")\n",
    "\n",
    "# Fare（運賃）の欠損値補完\n",
    "# Pclass、Embarked、Ticket_Prefixベースで中央値補完\n",
    "df_all['Fare'] = df_all.groupby(['Pclass', 'Embarked'])['Fare'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "df_all['Fare'] = df_all['Fare'].fillna(df_all['Fare'].median())\n",
    "df_all['Fare_Per_Person'] = df_all['Fare_Per_Person'].fillna(df_all['Fare_Per_Person'].median())\n",
    "\n",
    "# Embarked（乗船港）の欠損値補完\n",
    "# 最頻値で補完\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna(df_all['Embarked'].mode()[0])\n",
    "\n",
    "print(\"\\n=== 欠損値補完完了 ===\")\n",
    "print(df_all.isnull().sum()[df_all.isnull().sum() > 0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Phase 6: 追加の特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 年齢グループ\n",
    "df_all['Age_Cat'] = pd.cut(df_all['Age'], \n",
    "                           bins=[0, 12, 18, 35, 60, 100],\n",
    "                           labels=['Child', 'Teen', 'Adult', 'MiddleAge', 'Senior'])\n",
    "\n",
    "# 運賃グループ\n",
    "df_all['Fare_Cat'] = pd.qcut(df_all['Fare'], q=5, labels=['VeryLow', 'Low', 'Medium', 'High', 'VeryHigh'])\n",
    "\n",
    "# Sex-Pclass交互作用\n",
    "df_all['Sex_Pclass'] = df_all['Sex'] + '_' + df_all['Pclass'].astype(str)\n",
    "\n",
    "# Age-Sex交互作用\n",
    "df_all['Age_Sex'] = df_all['Age_Cat'].astype(str) + '_' + df_all['Sex']\n",
    "\n",
    "# Title-Pclass交互作用\n",
    "df_all['Title_Pclass'] = df_all['Title_Grouped'].astype(str) + '_' + df_all['Pclass'].astype(str)\n",
    "\n",
    "# 生存優先度スコア（ドメイン知識）\n",
    "df_all['Priority_Score'] = 0\n",
    "df_all.loc[df_all['Sex'] == 'female', 'Priority_Score'] += 100\n",
    "df_all.loc[df_all['Is_Child'] == 1, 'Priority_Score'] += 80\n",
    "df_all.loc[df_all['Pclass'] == 1, 'Priority_Score'] += 30\n",
    "df_all.loc[df_all['Pclass'] == 2, 'Priority_Score'] += 15\n",
    "df_all.loc[df_all['Is_Mother'] == 1, 'Priority_Score'] += 20\n",
    "\n",
    "# 社会経済的地位スコア\n",
    "df_all['SES_Score'] = (\n",
    "    (4 - df_all['Pclass']) * 30 +  # クラスの逆数\n",
    "    df_all['Fare_Per_Person'].rank(pct=True) * 100 +  # 運賃ランク\n",
    "    df_all['Has_Cabin'] * 50  # 客室保有\n",
    ")\n",
    "\n",
    "# 名前の長さ（社会的地位の代理指標）\n",
    "df_all['Name_Length'] = df_all['Name'].str.len()\n",
    "\n",
    "# チケット文字列の長さ\n",
    "df_all['Ticket_Length'] = df_all['Ticket'].str.len()\n",
    "\n",
    "print(\"=== 追加特徴量作成完了 ===\")\n",
    "print(f\"\\n作成された特徴量数: {len(df_all.columns)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔢 Phase 7: カテゴリカル変数のエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# カテゴリカル変数のリスト\n",
    "categorical_cols = [\n",
    "    'Sex', 'Embarked', 'Title_Grouped', 'Deck', 'Cabin_Position',\n",
    "    'Ticket_Prefix_Grouped', 'FamilySize_Cat', 'Family_Type',\n",
    "    'Age_Cat', 'Fare_Cat', 'Sex_Pclass', 'Age_Sex', 'Title_Pclass'\n",
    "]\n",
    "\n",
    "# Label Encoding\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in df_all.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_all[col + '_Encoded'] = le.fit_transform(df_all[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "print(\"カテゴリカルエンコーディング完了\")\n",
    "print(f\"エンコードされた変数: {len(categorical_cols)}個\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Phase 8: モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 訓練データとテストデータの分割\n",
    "train_processed = df_all[df_all['is_train']].copy()\n",
    "test_processed = df_all[~df_all['is_train']].copy()\n",
    "\n",
    "# 使用する特徴量の選択\n",
    "exclude_cols = [\n",
    "    'PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived', 'is_train',\n",
    "    'Surname', 'Title', 'Ticket_Cleaned', 'Ticket_Number',\n",
    "    # カテゴリカル変数（エンコード済みを使用）\n",
    "    'Sex', 'Embarked', 'Title_Grouped', 'Deck', 'Cabin_Position',\n",
    "    'Ticket_Prefix', 'Ticket_Prefix_Grouped', 'FamilySize_Cat', 'Family_Type',\n",
    "    'Age_Cat', 'Fare_Cat', 'Sex_Pclass', 'Age_Sex', 'Title_Pclass'\n",
    "]\n",
    "\n",
    "feature_cols = [col for col in df_all.columns \n",
    "                if col not in exclude_cols and \n",
    "                df_all[col].dtype in ['int64', 'float64', 'int32', 'float32', 'int8', 'int16']]\n",
    "\n",
    "# NaN処理\n",
    "for col in feature_cols:\n",
    "    if train_processed[col].isnull().any():\n",
    "        train_processed[col] = train_processed[col].fillna(train_processed[col].median())\n",
    "        test_processed[col] = test_processed[col].fillna(train_processed[col].median())\n",
    "\n",
    "X_train = train_processed[feature_cols]\n",
    "y_train = train_processed['Survived']\n",
    "X_test = test_processed[feature_cols]\n",
    "\n",
    "print(f\"使用する特徴量数: {len(feature_cols)}\")\n",
    "print(f\"\\nTop 20特徴量:\")\n",
    "for i, col in enumerate(feature_cols[:20], 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# LightGBMモデル（exp004の設定ベース + 改良）\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'min_child_samples': 20,\n",
    "    'min_split_gain': 0.01,\n",
    "    'min_child_weight': 0.001,\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 1000,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# 5-fold Cross Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "oof_predictions = np.zeros(len(X_train))\n",
    "test_predictions = np.zeros(len(X_test))\n",
    "feature_importance = np.zeros(len(feature_cols))\n",
    "\n",
    "print(\"\\n=== 5-Fold Cross Validation ===\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # モデル訓練\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # 予測\n",
    "    val_pred_proba = model.predict(X_val)\n",
    "    val_pred = (val_pred_proba >= 0.5).astype(int)\n",
    "    test_pred_proba = model.predict(X_test)\n",
    "    \n",
    "    # スコア計算\n",
    "    fold_score = accuracy_score(y_val, val_pred)\n",
    "    cv_scores.append(fold_score)\n",
    "    \n",
    "    # 予測値保存\n",
    "    oof_predictions[val_idx] = val_pred_proba\n",
    "    test_predictions += test_pred_proba / 5\n",
    "    \n",
    "    # 特徴量重要度\n",
    "    feature_importance += model.feature_importances_ / 5\n",
    "    \n",
    "    print(f\"Fold {fold}: {fold_score:.4f} (trees: {model.n_estimators_})\")\n",
    "\n",
    "# 結果サマリー\n",
    "cv_mean = np.mean(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "oof_score = accuracy_score(y_train, (oof_predictions >= 0.5).astype(int))\n",
    "\n",
    "print(f\"\\n=== Cross Validation結果 ===\")\n",
    "print(f\"CV Mean: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "print(f\"OOF Score: {oof_score:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 特徴量重要度分析\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=== Top 20 重要特徴量 ===\")\n",
    "for i, row in importance_df.head(20).iterrows():\n",
    "    print(f\"{importance_df.index.get_loc(i)+1:2d}. {row['feature']:30s}: {row['importance']:8.2f}\")\n",
    "\n",
    "# 新規特徴量の重要度確認\n",
    "new_features = [\n",
    "    'Priority_Score', 'SES_Score', 'Surname_Survival_Rate', \n",
    "    'Ticket_Group_Size', 'Fare_Per_Person', 'Deck_Num',\n",
    "    'Is_Mother', 'Is_Father', 'Is_Child'\n",
    "]\n",
    "\n",
    "print(\"\\n=== 新規特徴量の重要度 ===\")\n",
    "for feat in new_features:\n",
    "    if feat in importance_df['feature'].values:\n",
    "        rank = importance_df.index.get_loc(importance_df[importance_df['feature'] == feat].index[0]) + 1\n",
    "        imp = importance_df[importance_df['feature'] == feat]['importance'].values[0]\n",
    "        print(f\"Rank {rank:3d}: {feat:25s}: {imp:8.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Phase 9: 結果分析と提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 過去実験との比較\n",
    "past_results = {\n",
    "    'exp001': {'cv': 0.8496, 'kaggle': 0.77272, 'features': 16},\n",
    "    'exp004': {'cv': 0.8462, 'kaggle': 0.77990, 'features': 23},\n",
    "    'exp006': {'cv': 0.8440, 'kaggle': 0.77272, 'features': 15},\n",
    "    'exp007': {'cv': None, 'kaggle': 0.77751, 'features': 25}\n",
    "}\n",
    "\n",
    "print(\"=== 過去実験との比較 ===\")\n",
    "for exp, results in past_results.items():\n",
    "    print(f\"{exp}: CV={results['cv']}, Kaggle={results['kaggle']:.5f}, Features={results['features']}\")\n",
    "\n",
    "print(f\"\\nexp008 (Advanced FE):\")\n",
    "print(f\"  CV Score: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "print(f\"  Features: {len(feature_cols)}\")\n",
    "\n",
    "# exp004基準での期待値計算\n",
    "exp004_ratio = past_results['exp004']['kaggle'] / past_results['exp004']['cv']\n",
    "expected_kaggle = cv_mean * exp004_ratio\n",
    "print(f\"  期待Kaggle Score: {expected_kaggle:.5f}\")\n",
    "\n",
    "if cv_mean > past_results['exp004']['cv']:\n",
    "    print(f\"\\n🎉 exp004のCVを上回った！ (+{cv_mean - past_results['exp004']['cv']:.4f})\")\n",
    "else:\n",
    "    print(f\"\\n📊 exp004のCVには及ばず ({cv_mean - past_results['exp004']['cv']:.4f})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 提出ファイル作成\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': (test_predictions >= 0.5).astype(int)\n",
    "})\n",
    "\n",
    "# 予測分布の確認\n",
    "print(\"=== 予測分布 ===\")\n",
    "print(f\"生存予測: {submission['Survived'].sum()} ({submission['Survived'].mean():.1%})\")\n",
    "print(f\"死亡予測: {len(submission) - submission['Survived'].sum()} ({1 - submission['Survived'].mean():.1%})\")\n",
    "print(f\"\\n訓練データ生存率: {y_train.mean():.1%}\")\n",
    "print(f\"テスト予測生存率: {submission['Survived'].mean():.1%}\")\n",
    "\n",
    "# ファイル保存\n",
    "import os\n",
    "os.makedirs('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/results/exp008', exist_ok=True)\n",
    "submission.to_csv('/Users/koki.ogai/Documents/ghq/github.com/oddgai/kaggle-projects/titanic/results/exp008/result.csv', index=False)\n",
    "\n",
    "print(f\"\\n✅ 提出ファイル保存完了\")\n",
    "print(f\"Path: results/exp008/result.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 実験サマリー\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"           🚀 EXP008 ADVANCED FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n📊 最終結果:\")\n",
    "print(f\"  CV Score: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "print(f\"  OOF Score: {oof_score:.4f}\")\n",
    "print(f\"  特徴量数: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\n🌟 主要な新特徴量:\")\n",
    "print(f\"  • Title詳細分類（Officer, Royalty, Dr, Rev）\")\n",
    "print(f\"  • Cabin詳細（デッキ、位置、複数客室）\")\n",
    "print(f\"  • Ticket分析（プレフィックス、グループサイズ）\")\n",
    "print(f\"  • Family詳細（Mother, Father, Family Type）\")\n",
    "print(f\"  • 高度な欠損値補完（RandomForest予測）\")\n",
    "\n",
    "print(f\"\\n💡 技術的改善点:\")\n",
    "print(f\"  • {len(feature_cols)}個の特徴量（過去最多）\")\n",
    "print(f\"  • 多様な交互作用特徴量\")\n",
    "print(f\"  • ドメイン知識と統計手法の融合\")\n",
    "\n",
    "print(f\"\\n🎯 期待Kaggleスコア: {expected_kaggle:.5f}\")\n",
    "if expected_kaggle > past_results['exp004']['kaggle']:\n",
    "    improvement = expected_kaggle - past_results['exp004']['kaggle']\n",
    "    print(f\"  → exp004を {improvement:.5f} 上回る見込み！🎉\")\n",
    "    print(f\"  → 0.78の壁突破の可能性！\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  Advanced Feature Engineering - The Devil is in the Details!\")\n",
    "print(\"  Kaggle提出をお待ちしています...\")\n",
    "print(\"=\"*70)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}