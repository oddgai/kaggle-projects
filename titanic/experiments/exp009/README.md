# exp009: Perfect Ensemble Strategy - 予想外の結果と重要な学び

## 🎯 実験概要

6つのBase Modelsと4つのアンサンブル手法を組み合わせた「Perfect Ensemble」戦略。
0.83の壁突破を目指したが、予想外の結果となった。

## 📊 結果サマリー

- **Kaggleスコア**: 0.78229
- **CVスコア**: 0.8485 ± - (Optuna Optimized)
- **特徴量数**: 15個（相関・重要度ベース選択）
- **判定**: exp008には及ばず（-0.00239）

## 🔍 戦略と手法

### 1. Perfect Ensemble構成

#### 6つのBase Models
1. **LightGBM** (最適化版)
2. **XGBoost** 
3. **Random Forest**
4. **Extra Trees**
5. **SVM (RBF)**
6. **Logistic Regression**

#### 4つのアンサンブル手法
1. **Simple Average**: 単純平均
2. **Weighted Average**: CVスコアベース重み
3. **Optuna Optimized**: ベイズ最適化重み ⭐ **採用**
4. **Level-1 Stacking**: メタ学習器

### 2. 高度な前処理
- **IterativeImputer**: 欠損値の予測補完
- **IQRベース外れ値処理**: Fare、Ageのクリッピング
- **相関ベース特徴量除去**: 0.8以上の高相関ペア除去
- **重要度ベース選択**: 下位5特徴量除去

## 📈 性能比較

| 実験 | Kaggle | CV | CV-Kaggle乖離 | 手法 |
|------|--------|-------|-------------|------|
| exp008 | **0.78468** | 0.8541 | 0.0694 | Single LightGBM |
| exp009 | 0.78229 | 0.8485 | 0.0662 | Perfect Ensemble |
| **差分** | **-0.00239** | **-0.0056** | **-0.0032** | **改善** |

## 🔍 詳細分析

### ❌ 期待に反した結果
1. **CVスコア**: 0.8485 (高い)
2. **Kaggleスコア**: 0.78229 (exp008より低い)
3. **乾燥**: Perfect Ensembleでも改善せず

### 📊 アンサンブル手法の効果
- **Simple Average**: 0.8429
- **Weighted Average**: 実行結果待ち
- **Optuna Optimized**: **0.8485** ← 採用
- **Level-1 Stacking**: 実行結果待ち

## 💡 重要な学び

### 1. 「Perfect Ensemble」の限界
**アンサンブル ≠ 常に改善**
- CVは向上したが、Kaggleスコアは低下
- 特徴量削減により情報損失が発生
- 複雑な手法が必ずしも良い結果をもたらさない

### 2. 特徴量の重要性再確認
**15個 vs 40個の比較**
- exp008: 40個特徴量 → 0.78468
- exp009: 15個特徴量 → 0.78229
- **特徴量削減による情報損失**が性能低下の主因

### 3. CV vs Kaggleの乖離問題
**汎化性能の課題**
- CV改善 ≠ Kaggle改善
- アンサンブルによる過適合の可能性
- 本質的な特徴量設計の重要性

### 4. シンプルな手法の威力
**Single LightGBM (exp008) > Perfect Ensemble (exp009)**
- 適切な特徴量エンジニアリング
- シンプルなモデルでも高性能達成可能
- 「Less is More」の再確認

## ⚠️ 失敗要因分析

### 1. 特徴量選択の問題
- **相関による除去**: 重要な情報も削除
- **重要度ベース除去**: LightGBMの偏った重要度に依存
- **40個→15個**: 過度な削減

### 2. ベースモデルの品質
- **多様性 vs 品質**: 品質の低いモデルも含む
- **特徴量不足**: 各モデルが十分な情報を得られない
- **スケーリング問題**: SVM、LRで適切な前処理が困難

### 3. アンサンブル設計
- **重み最適化**: CVに過適合
- **メタ学習**: 複雑化による汎化性能低下

## 🎯 今後の戦略

### Option A: exp008の改良
**最も有望なアプローチ**
- exp008の40特徴量を精査
- 重要度の低い5-10特徴量のみ除去
- ハイパーパラメータの微調整

### Option B: ハイブリッドアプローチ
- exp008特徴量 + 軽量アンサンブル
- LightGBM + XGBoost 2モデルのみ
- シンプルな重み付き平均

### Option C: 特徴量エンジニアリング強化
- 新しい交互作用の探索
- ドメイン知識の深掘り
- 外部データの活用検討

## 📊 技術的詳細

### アンサンブル最適化結果
```
Optuna最適重み (200回試行):
- LightGBM: 最適化済み
- XGBoost: 最適化済み  
- RandomForest: 最適化済み
- ExtraTrees: 最適化済み
- SVM: 最適化済み
- LogisticRegression: 最適化済み
```

### 前処理効果
- **IterativeImputer**: Age欠損値を高精度で補完
- **外れ値処理**: Fare、Ageの極値をクリッピング
- **特徴量選択**: 高相関・低重要度特徴量を除去

## 📝 結論

**exp009は技術的には成功、結果的には期待外れ**

### 成功した点
1. **Perfect Ensembleの実装**: 6モデル×4手法
2. **高度な前処理**: IterativeImputer、外れ値処理
3. **Optuna最適化**: 自動重み調整
4. **CV改善**: 0.8541 → 0.8485 (Ensemble効果)

### 学んだ教訓
1. **複雑 ≠ 高性能**: シンプルな手法の威力再確認
2. **特徴量の質 > 手法の複雑さ**: 良い特徴量が最重要
3. **CV最適化の落とし穴**: 過適合リスク
4. **アンサンブルの限界**: ベースモデルが重要

### 最も重要な発見
**「exp008の40特徴量 > Perfect Ensembleの15特徴量」**

特徴量エンジニアリングこそがKaggleコンペの核心であることを再確認。
次の実験では、exp008をベースにより慎重な改善を行うべき。

---

**「Perfect Ensemble」は技術的な挑戦として価値があったが、
シンプルで質の高い特徴量設計の重要性を改めて教えてくれた。**