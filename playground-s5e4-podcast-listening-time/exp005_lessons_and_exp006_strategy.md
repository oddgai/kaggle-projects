# exp005の教訓とexp006戦略

## exp005結果分析

### スコア比較
| 指標 | exp003 | exp004 | exp005 |
|------|--------|--------|--------|
| **CV RMSE** | 12.7938 | 12.8203 | **10.2268** ⚠️ |
| **Public Score** | **12.94051** | 12.96794 | 13.10978 |
| **Private Score** | **12.85914** | 12.87623 | 13.00859 |
| **CV-Kaggle Gap** | 0.1467 | 0.1476 | **2.8830** ⚠️ |

### 重要な発見

#### ✅ 成功した点
1. **高度な特徴量エンジニアリング**: 20+個の特徴量作成技術
2. **CatBoostモデル追加**: 第3のモデルとしての価値
3. **データ型最適化**: 適切な前処理手法
4. **アンサンブル手法**: 3モデルの組み合わせ

#### ❌ 失敗した点（オーバーフィッティング要因）
1. **過度な外れ値除去**: 75万→54万行（28%削減は多すぎ）
2. **複雑すぎる特徴量**: 20+個が訓練データに特化
3. **ターゲットエンコーディング**: CVでのリーク可能性
4. **検証方法**: 3-fold CVでは不十分だった
5. **正規化の問題**: CatBoostと他モデルで異なる前処理

### オーバーフィッティング分析

```
CV RMSE: 10.2268 (訓練データに最適化)
Public Score: 13.10978 (本番データで悪化)
Gap: 2.8830 (異常に大きい乖離)
```

**典型的なオーバーフィッティングパターン**

## exp006戦略: "Less is More" アプローチ

### 基本方針
- **シンプルさ重視**: 複雑さを削減
- **堅牢性確保**: CV-Kaggle乖離を最小化  
- **データ保持**: 外れ値除去を最小限に
- **検証強化**: より厳密なCV検証

### 具体的改善点

#### 1. 外れ値処理の最適化
```python
# exp005: 28%削減（過度）
outlier_factor = 1.5  # 厳しすぎ

# exp006: 10%程度の削減
outlier_factor = 3.0  # 緩和
# または上位/下位1%のみ除去
```

#### 2. 特徴量エンジニアリングの簡素化
```python
# exp005: 20+個の複雑な特徴量
# exp006: 厳選した10個程度

重要な特徴量のみ：
1. Episode_Length_squared, Episode_Length_log
2. Host_Guest_Popularity_Sum, Host_Guest_Popularity_Ratio  
3. Ad_Density, Ads_per_Hour
4. Is_Weekend, Hour_of_Day (数値変換)
5. Genre_Mean_Length (統計量1個のみ)
```

#### 3. ターゲットエンコーディングの改善
```python
# exp005: リーク可能性
# exp006: Holdout方式での厳密な検証

from category_encoders import TargetEncoder
# より安全な実装
```

#### 4. クロスバリデーション強化
```python
# exp005: 3-fold CV（不十分）
# exp006: 5-fold CV + Stratified分割

from sklearn.model_selection import StratifiedKFold
# より厳密な検証
```

#### 5. 正則化の強化
```python
# 各モデルで正則化パラメータを強化
lgb_params['reg_alpha'] = 1.0
lgb_params['reg_lambda'] = 1.0

xgb_params['reg_alpha'] = 2.0  
xgb_params['reg_lambda'] = 2.0

cat_params['reg_lambda'] = 5.0
```

### exp006実装計画

#### Phase 1: データ前処理の改善
- 外れ値除去を緩和（3σ法または上下1%）
- 欠損値処理の見直し
- より慎重なターゲットエンコーディング

#### Phase 2: 特徴量の厳選
- 重要度分析による特徴量選択
- 10個程度の厳選された特徴量
- 相関の高い特徴量の除去

#### Phase 3: モデリングの改善
- 正則化パラメータの強化
- Early stoppingの最適化
- 5-fold CVでの厳密な検証

#### Phase 4: アンサンブルの改良
- 2モデル（LGB+XGB）での検証
- CatBoostの効果を慎重に評価
- 重み最適化の導入

### 期待される効果

| 指標 | exp005 | exp006目標 |
|------|--------|-------------|
| **CV RMSE** | 10.2268 | 12.3-12.5 |
| **Public Score** | 13.10978 | **12.2-12.4** |
| **CV-Kaggle Gap** | 2.8830 | **< 0.3** |

### 成功指標

1. **CV-Kaggle Gap < 0.3**: オーバーフィッティング解消
2. **Public Score < 12.5**: exp003/004を超える
3. **安定性確保**: CV標準偏差 < 0.05
4. **再現性**: 複数回実行で安定した結果

## 教訓のまとめ

### 重要な学び
1. **CVスコアの改善 ≠ Kaggleスコアの改善**
2. **複雑さは必ずしも性能向上をもたらさない**  
3. **データ削減は慎重に行うべき**
4. **検証方法の設計が最重要**
5. **シンプルさと堅牢性の価値**

### 今後の指針
- "Less is More" - シンプルさを重視
- データを大切に - 過度な削減を避ける  
- 検証を厳密に - CV設計の重要性
- 段階的改善 - 一度に多くを変えない
- 結果の解釈 - スコアの背景を理解する

**exp006では、exp005で得た技術知識を活かしつつ、より慎重で堅牢なアプローチを取る。**