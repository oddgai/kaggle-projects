#!/usr/bin/env python3
"""
å®Ÿé¨“003: Optunaã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
Playground Series S5E4: ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆè´å–æ™‚é–“äºˆæ¸¬
exp002ã®XGBoostãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€Optunaã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
import pickle
import json
import optuna
from optuna.samplers import TPESampler

from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.impute import SimpleImputer
import xgboost as xgb

warnings.filterwarnings('ignore')

# è¡¨ç¤ºè¨­å®š
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)

# ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
sns.set_style('whitegrid')
plt.style.use('default')

# ã‚·ãƒ¼ãƒ‰å€¤ã®è¨­å®š
np.random.seed(42)

print("=== å®Ÿé¨“003é–‹å§‹ï¼ˆOptunaãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼‰===")

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
data_dir = Path('../../data')

train_df = pd.read_csv(data_dir / 'train.csv')
test_df = pd.read_csv(data_dir / 'test.csv')
sample_submission = pd.read_csv(data_dir / 'sample_submission.csv')

print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_df.shape}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_df.shape}")

# ç›®æ¨™å¤‰æ•°ã®ç¢ºèª
target_col = 'Listening_Time_minutes'

def enhanced_preprocess_data(df, is_train=True, target_col='Listening_Time_minutes', target_encoder=None):
    """
    æ‹¡å¼µã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’è¡Œã†é–¢æ•°ï¼ˆexp002ã¨åŒã˜ï¼‰
    """
    # ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼
    df_processed = df.copy()
    
    # IDã‚«ãƒ©ãƒ ã‚’ä¿å­˜
    ids = None
    if 'id' in df_processed.columns:
        ids = df_processed['id']
        df_processed = df_processed.drop('id', axis=1)
    
    # ç›®æ¨™å¤‰æ•°ã®åˆ†é›¢ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å ´åˆï¼‰
    if is_train and target_col in df_processed.columns:
        y = df_processed[target_col]
        df_processed = df_processed.drop(target_col, axis=1)
    else:
        y = None
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¨æ•°å€¤å¤‰æ•°ã‚’åˆ†é›¢
    categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()
    numerical_cols = df_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()
    
    # æ•°å€¤å¤‰æ•°ã®æ¬ æå€¤è£œå®Œ
    for col in numerical_cols:
        if df_processed[col].isnull().sum() > 0:
            median_value = df_processed[col].median()
            df_processed[col] = df_processed[col].fillna(median_value)
    
    # Guest_Popularity_percentageã®æ¬ æå€¤ã‚’0ã§è£œå®Œï¼ˆã‚²ã‚¹ãƒˆãªã—ã‚’æ„å‘³ï¼‰
    df_processed['Guest_Popularity_percentage'] = df_processed['Guest_Popularity_percentage'].fillna(0)
    
    # åŸºæœ¬çš„ãªæ–°è¦ç‰¹å¾´é‡ã®ä½œæˆ
    df_processed['Ad_Density'] = df_processed['Number_of_Ads'] / (df_processed['Episode_Length_minutes'] + 1e-8)
    df_processed['Host_Guest_Popularity_Diff'] = (df_processed['Host_Popularity_percentage'] - 
                                                   df_processed['Guest_Popularity_percentage'])
    df_processed['Has_Guest'] = (df_processed['Guest_Popularity_percentage'] > 0).astype(int)
    
    # æ–°ã—ã„ç‰¹å¾´é‡ã®ä½œæˆ
    df_processed['Episode_Length_squared'] = df_processed['Episode_Length_minutes'] ** 2
    df_processed['Episode_Length_log'] = np.log(df_processed['Episode_Length_minutes'] + 1)
    df_processed['Host_Guest_Popularity_Sum'] = df_processed['Host_Popularity_percentage'] + df_processed['Guest_Popularity_percentage']
    df_processed['Host_Guest_Popularity_Ratio'] = df_processed['Host_Popularity_percentage'] / (df_processed['Guest_Popularity_percentage'] + 1)
    df_processed['Ads_per_Hour'] = df_processed['Number_of_Ads'] / ((df_processed['Episode_Length_minutes'] / 60) + 1e-8)
    df_processed['Has_Ads'] = (df_processed['Number_of_Ads'] > 0).astype(int)
    df_processed['Episode_Length_Category'] = pd.cut(df_processed['Episode_Length_minutes'], 
                                                     bins=[0, 30, 60, 90, float('inf')], 
                                                     labels=['short', 'medium', 'long', 'very_long'])
    
    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®å‰å‡¦ç†
    le_dict = {}
    for col in categorical_cols:
        le = LabelEncoder()
        df_processed[col] = df_processed[col].fillna('Missing')
        df_processed[col] = le.fit_transform(df_processed[col])
        le_dict[col] = le
    
    # Episode_Length_Categoryã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    le_length_cat = LabelEncoder()
    df_processed['Episode_Length_Category'] = le_length_cat.fit_transform(df_processed['Episode_Length_Category'])
    le_dict['Episode_Length_Category'] = le_length_cat
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã®ã¿ï¼‰
    if is_train and y is not None and target_encoder is None:
        target_encoding_cols = ['Podcast_Name', 'Episode_Title', 'Genre']
        target_encoder = {}
        
        for col in target_encoding_cols:
            if col in categorical_cols:
                # å„ã‚«ãƒ†ã‚´ãƒªã®å¹³å‡å€¤ã‚’è¨ˆç®—ï¼ˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ä»˜ãï¼‰
                global_mean = y.mean()
                category_means = df_processed.groupby(col)[col].apply(lambda x: len(x))
                category_targets = pd.DataFrame({'original_col': df_processed[col], 'target': y})
                category_target_mean = category_targets.groupby('original_col')['target'].mean()
                
                # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆÎ±=10ï¼‰
                alpha = 10
                smoothed_means = (category_target_mean * category_means + global_mean * alpha) / (category_means + alpha)
                
                target_encoder[col] = smoothed_means
                df_processed[f'{col}_target_encoded'] = df_processed[col].map(target_encoder[col]).fillna(global_mean)
    
    elif target_encoder is not None:
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€ä¿å­˜ã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨
        for col, encoder in target_encoder.items():
            if col in df_processed.columns:
                global_mean = encoder.mean()  # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤
                df_processed[f'{col}_target_encoded'] = df_processed[col].map(encoder).fillna(global_mean)
    
    return df_processed, y, ids, le_dict, target_encoder if is_train else None

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†å®Ÿè¡Œ
print("\n=== ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç† ===")
X_train_processed, y_train, train_ids, le_dict_train, target_encoder = enhanced_preprocess_data(train_df, is_train=True)
X_test_processed, _, test_ids, _, _ = enhanced_preprocess_data(test_df, is_train=False, target_encoder=target_encoder)

print(f"å‡¦ç†å¾Œã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_train_processed.shape}")
print(f"å‡¦ç†å¾Œã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_test_processed.shape}")

# Optunaã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
def objective(trial):
    """
    Optunaæœ€é©åŒ–ã®ç›®çš„é–¢æ•°
    """
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¢ç´¢ç¯„å›²ã‚’å®šç¾©
    params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'booster': 'gbtree',
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),
        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 2.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 2.0),
        'random_state': 42,
        'n_jobs': -1,
        'verbosity': 0
    }
    
    # 5-fold Cross Validation
    kfold = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = []
    
    for train_idx, val_idx in kfold.split(X_train_processed):
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        X_fold_train, X_fold_val = X_train_processed.iloc[train_idx], X_train_processed.iloc[val_idx]
        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        fold_train_data = xgb.DMatrix(X_fold_train, label=y_fold_train)
        fold_val_data = xgb.DMatrix(X_fold_val, label=y_fold_val)
        
        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        num_boost_round = trial.suggest_int('num_boost_round', 100, 3000)
        fold_model = xgb.train(
            params,
            fold_train_data,
            num_boost_round=num_boost_round,
            evals=[(fold_val_data, 'eval')],
            early_stopping_rounds=100,
            verbose_eval=0
        )
        
        # äºˆæ¸¬ã¨è©•ä¾¡
        fold_pred = fold_model.predict(fold_val_data, iteration_range=(0, fold_model.best_iteration))
        fold_rmse = np.sqrt(mean_squared_error(y_fold_val, fold_pred))
        cv_scores.append(fold_rmse)
    
    return np.mean(cv_scores)

# Optunaæœ€é©åŒ–ã®å®Ÿè¡Œ
print("\n=== Optunaã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–é–‹å§‹ ===")
print("è©¦è¡Œå›æ•°: 100å›")

study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))
study.optimize(objective, n_trials=100, timeout=3600)  # 1æ™‚é–“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

print("\n=== æœ€é©åŒ–çµæœ ===")
print(f"æœ€é©ã‚¹ã‚³ã‚¢ (CV RMSE): {study.best_value:.4f}")
print(f"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {study.best_params}")

# æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´
print("\n=== æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´ ===")
best_params = study.best_params.copy()
num_boost_round = best_params.pop('num_boost_round')

# è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
X_train, X_val, y_train_split, y_val = train_test_split(
    X_train_processed, y_train, 
    test_size=0.2, 
    random_state=42
)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
train_data = xgb.DMatrix(X_train, label=y_train_split)
val_data = xgb.DMatrix(X_val, label=y_val)

# æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«è¨“ç·´
best_params.update({
    'objective': 'reg:squarederror',
    'eval_metric': 'rmse',
    'booster': 'gbtree',
    'random_state': 42,
    'n_jobs': -1
})

final_model = xgb.train(
    best_params,
    train_data,
    evals=[(train_data, 'train'), (val_data, 'eval')],
    num_boost_round=num_boost_round,
    early_stopping_rounds=100,
    verbose_eval=100
)

# æœ€çµ‚è©•ä¾¡
y_train_pred = final_model.predict(xgb.DMatrix(X_train), iteration_range=(0, final_model.best_iteration))
y_val_pred = final_model.predict(xgb.DMatrix(X_val), iteration_range=(0, final_model.best_iteration))

train_rmse = np.sqrt(mean_squared_error(y_train_split, y_train_pred))
train_mae = mean_absolute_error(y_train_split, y_train_pred)
train_r2 = r2_score(y_train_split, y_train_pred)

val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))
val_mae = mean_absolute_error(y_val, y_val_pred)
val_r2 = r2_score(y_val, y_val_pred)

print(f"\n=== æœ€çµ‚è©•ä¾¡çµæœ ===")
print(f"è¨“ç·´RMSE: {train_rmse:.4f}")
print(f"æ¤œè¨¼RMSE: {val_rmse:.4f}")
print(f"CVæœ€é©ã‚¹ã‚³ã‚¢: {study.best_value:.4f}")

# æœ€çµ‚Cross Validationï¼ˆæœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ï¼‰
print("\n=== æœ€çµ‚5-Fold Cross Validation ===")
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
final_cv_scores = []

for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_processed)):
    print(f"Fold {fold + 1}/5")
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    X_fold_train, X_fold_val = X_train_processed.iloc[train_idx], X_train_processed.iloc[val_idx]
    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    fold_train_data = xgb.DMatrix(X_fold_train, label=y_fold_train)
    fold_val_data = xgb.DMatrix(X_fold_val, label=y_fold_val)
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    fold_model = xgb.train(
        best_params,
        fold_train_data,
        evals=[(fold_train_data, 'train'), (fold_val_data, 'eval')],
        num_boost_round=num_boost_round,
        early_stopping_rounds=100,
        verbose_eval=0
    )
    
    # äºˆæ¸¬ã¨è©•ä¾¡
    fold_pred = fold_model.predict(fold_val_data, iteration_range=(0, fold_model.best_iteration))
    fold_rmse = np.sqrt(mean_squared_error(y_fold_val, fold_pred))
    final_cv_scores.append(fold_rmse)
    
    print(f"Fold {fold + 1} RMSE: {fold_rmse:.4f}")

cv_mean = np.mean(final_cv_scores)
cv_std = np.std(final_cv_scores)

print(f"\n=== æœ€çµ‚Cross Validationçµæœ ===")
print(f"å¹³å‡RMSE: {cv_mean:.4f} Â± {cv_std:.4f}")
print(f"å„Foldã®RMSE: {[f'{score:.4f}' for score in final_cv_scores]}")

# ç‰¹å¾´é‡é‡è¦åº¦ã®å–å¾—
feature_importance = final_model.get_score(importance_type='gain')
feature_names = X_train_processed.columns

importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': [feature_importance.get(f'f{i}', 0) for i in range(len(feature_names))]
}).sort_values('importance', ascending=False)

print("\n=== ç‰¹å¾´é‡é‡è¦åº¦ Top 15 ===")
print(importance_df.head(15))

# å¯è¦–åŒ–
plt.figure(figsize=(12, 8))
top_features = importance_df.head(20)
sns.barplot(data=top_features, x='importance', y='feature')
plt.title('ç‰¹å¾´é‡é‡è¦åº¦ Top 20 (XGBoostæœ€é©åŒ– - exp003)')
plt.xlabel('é‡è¦åº¦')
plt.tight_layout()
plt.savefig('feature_importance_plot.png', dpi=80, bbox_inches='tight')
print("ç‰¹å¾´é‡é‡è¦åº¦ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜")

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
test_data = xgb.DMatrix(X_test_processed)
test_predictions = final_model.predict(test_data, iteration_range=(0, final_model.best_iteration))

# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
submission_df = pd.DataFrame({
    'id': test_ids,
    target_col: test_predictions
})

# ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
results_dir = Path('../../results/exp003')
results_dir.mkdir(parents=True, exist_ok=True)

submission_path = results_dir / 'submission.csv'
submission_df.to_csv(submission_path, index=False)
print(f"\næå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: {submission_path}")

# ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
model_path = results_dir / 'model.pkl'
with open(model_path, 'wb') as f:
    pickle.dump(final_model, f)
print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {model_path}")

# å®Ÿé¨“çµæœã®è¨˜éŒ²
experiment_results = {
    'experiment_id': 'exp003',
    'model_type': 'XGBoost_Optimized',
    'optimization_method': 'Optuna',
    'n_trials': study.n_trials,
    'model_params': best_params,
    'best_num_boost_round': num_boost_round,
    
    # ç‰¹å¾´é‡æƒ…å ±
    'features': list(X_train_processed.columns),
    'num_features': len(X_train_processed.columns),
    'new_features': ['Ad_Density', 'Host_Guest_Popularity_Diff', 'Has_Guest', 
                    'Episode_Length_squared', 'Episode_Length_log',
                    'Host_Guest_Popularity_Sum', 'Host_Guest_Popularity_Ratio',
                    'Ads_per_Hour', 'Has_Ads', 'Episode_Length_Category'],
    
    # è©•ä¾¡æŒ‡æ¨™
    'train_rmse': float(train_rmse),
    'train_mae': float(train_mae),
    'train_r2': float(train_r2),
    'val_rmse': float(val_rmse),
    'val_mae': float(val_mae),
    'val_r2': float(val_r2),
    
    # Cross Validationçµæœ
    'cv_scores': [float(score) for score in final_cv_scores],
    'cv_rmse_mean': float(cv_mean),
    'cv_rmse_std': float(cv_std),
    'optuna_best_score': float(study.best_value),
    
    # ç‰¹å¾´é‡é‡è¦åº¦
    'feature_importance': {
        row['feature']: int(row['importance']) if row['importance'] > 0 else 0
        for _, row in importance_df.iterrows()
    },
    
    # Kaggleã‚¹ã‚³ã‚¢ï¼ˆæ‰‹å‹•ã§æ›´æ–°ï¼‰
    'public_score': None,
    'private_score': None,
    
    # ãƒ‡ãƒ¼ã‚¿æƒ…å ±
    'train_size': len(X_train_processed),
    'test_size': len(X_test_processed),
    'target_variable': target_col,
    
    # å®Ÿé¨“è¨­å®š
    'cv_folds': 5,
    'validation_split': 0.2,
    'random_state': 42,
    'preprocessing': {
        'missing_value_strategy': 'median_imputation',
        'categorical_encoding': 'label_encoding_and_target_encoding',
        'feature_engineering': 'enhanced_features,target_encoding,polynomial_features'
    }
}

# å®Ÿé¨“çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
results_json_path = results_dir / 'experiment_results.json'
with open(results_json_path, 'w', encoding='utf-8') as f:
    json.dump(experiment_results, f, indent=2, ensure_ascii=False)
print(f"å®Ÿé¨“çµæœã‚’ä¿å­˜: {results_json_path}")

print("\n=== å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼ ===")
print(f"ãƒ¢ãƒ‡ãƒ«: {experiment_results['model_type']}")
print(f"æœ€é©åŒ–è©¦è¡Œå›æ•°: {study.n_trials}")
print(f"ç‰¹å¾´é‡æ•°: {len(experiment_results['features'])}å€‹")
print(f"æ¤œè¨¼RMSE: {experiment_results['val_rmse']:.4f}")
print(f"CVå¹³å‡RMSE: {experiment_results['cv_rmse_mean']:.4f} Â± {experiment_results['cv_rmse_std']:.4f}")
print(f"Optunaæœ€é©ã‚¹ã‚³ã‚¢: {experiment_results['optuna_best_score']:.4f}")

print(f"\nå‰å®Ÿé¨“ã¨ã®æ¯”è¼ƒ:")
print(f"exp001 CV RMSE: 13.0023")
print(f"exp002 CV RMSE: 12.8926")
print(f"exp003 CV RMSE: {experiment_results['cv_rmse_mean']:.4f}")
improvement_from_002 = 12.8926 - experiment_results['cv_rmse_mean']
improvement_from_001 = 13.0023 - experiment_results['cv_rmse_mean']
print(f"exp002ã‹ã‚‰ã®æ”¹å–„åº¦: {improvement_from_002:.4f}")
print(f"exp001ã‹ã‚‰ã®æ”¹å–„åº¦: {improvement_from_001:.4f}")

# ç›®æ¨™é”æˆç¢ºèª
if experiment_results['cv_rmse_mean'] < 12.0:
    print(f"\nğŸ‰ ç›®æ¨™é”æˆï¼ CV RMSE {experiment_results['cv_rmse_mean']:.4f} < 12.0")
else:
    print(f"\nâš ï¸  ã¾ã ç›®æ¨™æœªé”æˆã€‚CV RMSE {experiment_results['cv_rmse_mean']:.4f} >= 12.0")
    print("exp004ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰ã§æ›´ãªã‚‹æ”¹å–„ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚")

print("\n=== å®Ÿé¨“003å®Œäº† ===")