#!/usr/bin/env python3
"""
exp007: Competition Insights Implementation
- é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆDiscussion insightsï¼‰
- XGBoost + CatBoost + LightGBM ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
- ã‚°ãƒ«ãƒ¼ãƒ—ãƒ™ãƒ¼ã‚¹çµ±è¨ˆé‡ã¨ç›¸äº’ä½œç”¨ç‰¹å¾´é‡
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostRegressor
import warnings
warnings.filterwarnings('ignore')

def load_data():
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    train = pd.read_csv('data/train.csv')
    test = pd.read_csv('data/test.csv')
    return train, test

def advanced_feature_engineering(df, is_train=True):
    """
    Competition insightsã«åŸºã¥ãé«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    """
    df = df.copy()
    
    # 1. åŸºæœ¬çš„ãªæ•°å€¤å¤‰æ›
    sentiment_map = {'Positive': 1, 'Neutral': 0, 'Negative': -1}
    df['Episode_Sentiment_num'] = df['Episode_Sentiment'].map(sentiment_map)
    
    # 2. æ™‚é–“ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡
    df['Is_Weekend'] = df['Publication_Day'].isin([5, 6]).astype(int)
    
    # Publication_Timeé †åºã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    time_order = {'Morning': 0, 'Afternoon': 1, 'Evening': 2, 'Night': 3}
    df['Publication_Time_ord'] = df['Publication_Time'].map(time_order)
    
    # 3. åºƒå‘Šå¯†åº¦ç‰¹å¾´é‡
    df['Ads_per_Minute'] = df['Number_of_Ads'] / (df['Episode_Length_minutes'] + 1)
    
    # 4. äººæ°—åº¦ç‰¹å¾´é‡
    df['Host_Popularity_per_Minute'] = df['Host_Popularity_percentage'] / (df['Episode_Length_minutes'] + 1)
    df['Guest_Popularity_per_Minute'] = df['Guest_Popularity_percentage'] / (df['Episode_Length_minutes'] + 1)
    df['Host_Guest_Popularity_Ratio'] = df['Host_Popularity_percentage'] / (df['Guest_Popularity_percentage'] + 1)
    df['Total_Popularity'] = df['Host_Popularity_percentage'] + df['Guest_Popularity_percentage']
    df['Popularity_Density'] = df['Total_Popularity'] / (df['Episode_Length_minutes'] + 1)
    
    # 5. ç›¸äº’ä½œç”¨ç‰¹å¾´é‡
    df['Length_Host_Interaction'] = df['Episode_Length_minutes'] * df['Host_Popularity_percentage']
    df['Length_Guest_Interaction'] = df['Episode_Length_minutes'] * df['Guest_Popularity_percentage']
    df['Length_Ads_Interaction'] = df['Episode_Length_minutes'] * df['Number_of_Ads']
    df['Ads_per_Host_Popularity'] = df['Number_of_Ads'] / (df['Host_Popularity_percentage'] + 1)
    df['Ads_per_Guest_Popularity'] = df['Number_of_Ads'] / (df['Guest_Popularity_percentage'] + 1)
    
    # 6. ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡
    df['Podcast_Name_Length'] = df['Podcast_Name'].str.len()
    df['Episode_Title_Length'] = df['Episode_Title'].str.len()
    df['Title_Name_Ratio'] = df['Episode_Title_Length'] / (df['Podcast_Name_Length'] + 1)
    
    # 7. ã‚°ãƒ«ãƒ¼ãƒ—ãƒ™ãƒ¼ã‚¹çµ±è¨ˆé‡ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—ï¼‰
    if is_train:
        # ã‚¸ãƒ£ãƒ³ãƒ«å¹³å‡
        genre_stats = df.groupby('Genre').agg({
            'Episode_Length_minutes': ['mean', 'std'],
            'Host_Popularity_percentage': 'mean',
            'Guest_Popularity_percentage': 'mean',
            'Number_of_Ads': 'mean'
        }).round(2)
        genre_stats.columns = ['_'.join(col) for col in genre_stats.columns]
        
        # ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆåçµ±è¨ˆ
        podcast_stats = df.groupby('Podcast_Name').agg({
            'Episode_Length_minutes': ['mean', 'std'],
            'Host_Popularity_percentage': 'mean',
            'Number_of_Ads': 'mean'
        }).round(2)
        podcast_stats.columns = ['Podcast_' + '_'.join(col) for col in podcast_stats.columns]
        
        # ä¿å­˜ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        genre_stats.to_csv('experiments/exp007/genre_stats.csv')
        podcast_stats.to_csv('experiments/exp007/podcast_stats.csv')
    else:
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯èª­ã¿è¾¼ã¿
        genre_stats = pd.read_csv('experiments/exp007/genre_stats.csv', index_col=0)
        podcast_stats = pd.read_csv('experiments/exp007/podcast_stats.csv', index_col=0)
    
    # ãƒžãƒ¼ã‚¸
    df = df.merge(genre_stats, left_on='Genre', right_index=True, how='left')
    df = df.merge(podcast_stats, left_on='Podcast_Name', right_index=True, how='left')
    
    # 8. ç›¸å¯¾ç‰¹å¾´é‡ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«å¹³å‡ã¨ã®å·®ï¼‰
    df['Length_vs_Genre_Mean'] = df['Episode_Length_minutes'] - df['Episode_Length_minutes_mean']
    df['Host_Pop_vs_Genre_Mean'] = df['Host_Popularity_percentage'] - df['Host_Popularity_percentage_mean']
    
    # 9. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if is_train:
        target_mean = df['Listening_Time_minutes'].mean()
        
        genre_target = df.groupby('Genre')['Listening_Time_minutes'].mean()
        podcast_target = df.groupby('Podcast_Name')['Listening_Time_minutes'].mean()
        
        genre_target.to_csv('experiments/exp007/genre_target.csv')
        podcast_target.to_csv('experiments/exp007/podcast_target.csv')
        
        df['Genre_Target_Encoded'] = df['Genre'].map(genre_target).fillna(target_mean)
        df['Podcast_Target_Encoded'] = df['Podcast_Name'].map(podcast_target).fillna(target_mean)
    else:
        genre_target = pd.read_csv('experiments/exp007/genre_target.csv', index_col=0)['Listening_Time_minutes']
        podcast_target = pd.read_csv('experiments/exp007/podcast_target.csv', index_col=0)['Listening_Time_minutes']
        
        target_mean = genre_target.mean()
        df['Genre_Target_Encoded'] = df['Genre'].map(genre_target).fillna(target_mean)
        df['Podcast_Target_Encoded'] = df['Podcast_Name'].map(podcast_target).fillna(target_mean)
    
    # 10. æ¬ æå€¤å‡¦ç†
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
    
    return df

def remove_outliers_iqr(df, target_col='Listening_Time_minutes', threshold=1.5):
    """IQRæ³•ã«ã‚ˆã‚‹ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ã‚¢é™¤åŽ»"""
    if target_col not in df.columns:
        return df
    
    Q1 = df[target_col].quantile(0.25)
    Q3 = df[target_col].quantile(0.75)
    IQR = Q3 - Q1
    
    lower_bound = Q1 - threshold * IQR
    upper_bound = Q3 + threshold * IQR
    
    initial_size = len(df)
    df_clean = df[(df[target_col] >= lower_bound) & (df[target_col] <= upper_bound)].copy()
    removed = initial_size - len(df_clean)
    
    print(f"ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ã‚¢é™¤åŽ»: {removed}ä»¶ ({removed/initial_size*100:.1f}%)")
    return df_clean

def get_feature_columns(df):
    """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ã®ç‰¹å¾´é‡ã‚«ãƒ©ãƒ å–å¾—"""
    exclude_cols = ['id', 'Listening_Time_minutes', 'Podcast_Name', 'Episode_Title', 
                   'Genre', 'Episode_Sentiment', 'Publication_Time', 'Publication_Day']
    
    # æ•°å€¤åž‹ã‚«ãƒ©ãƒ ã®ã¿ã‚’é¸æŠž
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    feature_cols = [col for col in numeric_cols if col not in exclude_cols]
    
    print(f"é™¤å¤–ã‚«ãƒ©ãƒ : {exclude_cols}")
    print(f"æ•°å€¤åž‹ã‚«ãƒ©ãƒ æ•°: {len(numeric_cols)}")
    
    return feature_cols

def train_models(X_train, y_train, X_valid, y_valid):
    """3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’"""
    models = {}
    predictions = {}
    
    # 1. XGBoostï¼ˆæœ€é«˜æ€§èƒ½ï¼‰
    xgb_params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'max_depth': 8,
        'learning_rate': 0.05,
        'n_estimators': 1000,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'random_state': 42,
        'n_jobs': -1
    }
    
    xgb_model = xgb.XGBRegressor(**xgb_params)
    xgb_model.fit(
        X_train, y_train,
        eval_set=[(X_valid, y_valid)],
        verbose=False
    )
    models['xgboost'] = xgb_model
    predictions['xgboost'] = xgb_model.predict(X_valid)
    
    # 2. LightGBM
    lgb_params = {
        'objective': 'regression',
        'metric': 'rmse',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'n_estimators': 1000,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'random_state': 42,
        'n_jobs': -1,
        'verbose': -1
    }
    
    lgb_model = lgb.LGBMRegressor(**lgb_params)
    lgb_model.fit(
        X_train, y_train,
        eval_set=[(X_valid, y_valid)],
        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]
    )
    models['lightgbm'] = lgb_model
    predictions['lightgbm'] = lgb_model.predict(X_valid)
    
    # 3. CatBoost
    cat_params = {
        'iterations': 1000,
        'learning_rate': 0.05,
        'depth': 8,
        'loss_function': 'RMSE',
        'random_seed': 42,
        'verbose': False,
        'early_stopping_rounds': 50
    }
    
    cat_model = CatBoostRegressor(**cat_params)
    cat_model.fit(
        X_train, y_train,
        eval_set=(X_valid, y_valid),
        use_best_model=True
    )
    models['catboost'] = cat_model
    predictions['catboost'] = cat_model.predict(X_valid)
    
    return models, predictions

def find_best_weights(predictions, y_valid):
    """æœ€é©ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿ã‚’æŽ¢ç´¢ï¼ˆã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼‰"""
    best_rmse = float('inf')
    best_weights = None
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ
    model_names = list(predictions.keys())
    
    # 3ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿çµ„ã¿åˆã‚ã›ã‚’è©¦ã™
    for w1 in np.arange(0.1, 1.0, 0.1):
        for w2 in np.arange(0.1, 1.0-w1, 0.1):
            w3 = 1.0 - w1 - w2
            if w3 < 0.1:
                continue
                
            weights = [w1, w2, w3]
            pred = np.zeros_like(y_valid)
            for i, model_name in enumerate(model_names):
                pred += weights[i] * predictions[model_name]
            
            rmse = np.sqrt(mean_squared_error(y_valid, pred))
            if rmse < best_rmse:
                best_rmse = rmse
                best_weights = weights
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç­‰é‡ã¿
    if best_weights is None:
        best_weights = [1/len(predictions)] * len(predictions)
    
    return np.array(best_weights)

def main():
    print("=== exp007: Competition Insightså®Ÿè£… ===")
    print("ç­‹è‚‰ã®ã‚ˆã†ã«å¼·åŠ›ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã§ã€œðŸ’ª")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    train, test = load_data()
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train.shape}")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test.shape}")
    
    # é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    print("\né«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ä¸­...")
    train_fe = advanced_feature_engineering(train, is_train=True)
    test_fe = advanced_feature_engineering(test, is_train=False)
    
    # ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ã‚¢é™¤åŽ»ï¼ˆIQRæ³•ï¼‰
    if 'Listening_Time_minutes' in train_fe.columns:
        train_clean = remove_outliers_iqr(train_fe)
    else:
        train_clean = train_fe
    
    # ç‰¹å¾´é‡é¸æŠž
    feature_cols = get_feature_columns(train_clean)
    print(f"\nä½¿ç”¨ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
    
    X = train_clean[feature_cols].values
    y = train_clean['Listening_Time_minutes'].values
    X_test = test_fe[feature_cols].values
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    X_test = scaler.transform(X_test)
    
    # 5-fold CV
    n_splits = 5
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    cv_scores = []
    all_models = []
    
    print(f"\n{n_splits}-fold Cross Validationé–‹å§‹...")
    for fold, (train_idx, valid_idx) in enumerate(kf.split(X), 1):
        print(f"\nFold {fold}/{n_splits}")
        
        X_train, X_valid = X[train_idx], X[valid_idx]
        y_train, y_valid = y[train_idx], y[valid_idx]
        
        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        models, predictions = train_models(X_train, y_train, X_valid, y_valid)
        
        # æœ€é©é‡ã¿æŽ¢ç´¢
        best_weights = find_best_weights(predictions, y_valid)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        ensemble_pred = np.zeros_like(y_valid)
        for i, model_name in enumerate(models.keys()):
            ensemble_pred += best_weights[i] * predictions[model_name]
            rmse = np.sqrt(np.mean((predictions[model_name] - y_valid) ** 2))
            print(f"  {model_name}: RMSE = {rmse:.6f} (weight: {best_weights[i]:.3f})")
        
        fold_rmse = np.sqrt(np.mean((ensemble_pred - y_valid) ** 2))
        cv_scores.append(fold_rmse)
        print(f"  Ensemble: RMSE = {fold_rmse:.6f}")
        
        all_models.append((models, best_weights))
    
    # CVçµæžœ
    mean_cv = np.mean(cv_scores)
    std_cv = np.std(cv_scores)
    print(f"\n=== CVçµæžœ ===")
    print(f"å¹³å‡RMSE: {mean_cv:.6f} Â± {std_cv:.6f}")
    print(f"Fold scores: {[f'{s:.6f}' for s in cv_scores]}")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ï¼ˆå…¨ãƒ•ã‚©ãƒ«ãƒ‰ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
    print("\nãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ä¸­...")
    test_preds = np.zeros((len(X_test), n_splits))
    
    for fold, (models, weights) in enumerate(all_models):
        fold_pred = np.zeros(len(X_test))
        for i, model_name in enumerate(models.keys()):
            fold_pred += weights[i] * models[model_name].predict(X_test)
        test_preds[:, fold] = fold_pred
    
    # æœ€çµ‚äºˆæ¸¬ï¼ˆå…¨ãƒ•ã‚©ãƒ«ãƒ‰ã®å¹³å‡ï¼‰
    final_predictions = test_preds.mean(axis=1)
    
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    submission = pd.DataFrame({
        'id': test['id'],
        'Listening_Time_minutes': final_predictions
    })
    submission.to_csv('results/exp007/submission.csv', index=False)
    print(f"\næå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: results/exp007/submission.csv")
    
    # äºˆæƒ³ã‚¹ã‚³ã‚¢
    predicted_public = mean_cv + 0.1  # æŽ§ãˆã‚ãªäºˆæƒ³
    print(f"\näºˆæƒ³Public Score: {predicted_public:.4f}")
    print("ç­‹è‚‰ã®ã‚ˆã†ãªå¼·åŠ›ãƒ¢ãƒ‡ãƒ«å®Œæˆã‚„ã€œï¼ðŸ’ª")
    
    return mean_cv, std_cv, predicted_public

if __name__ == "__main__":
    cv_mean, cv_std, predicted_public = main()