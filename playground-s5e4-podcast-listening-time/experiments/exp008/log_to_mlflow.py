#!/usr/bin/env python3
"""
exp008ã®MLflowè¨˜éŒ²
Ultra-Optimized LightGBM with Optuna & Advanced Feature Engineering
"""

import mlflow
import json
from datetime import datetime
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from src.mlflow_utils import setup_mlflow, get_experiment_url

def log_exp008_to_mlflow():
    """exp008ã‚’MLflowã«è¨˜éŒ²"""
    
    # MLflowè¨­å®šï¼ˆå¤–éƒ¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨ï¼‰
    experiment_path, environment = setup_mlflow()
    
    # å®Ÿé¨“åã¨ã‚¿ã‚°
    run_name = f"exp008_{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    with mlflow.start_run(run_name=run_name):
        # åŸºæœ¬æƒ…å ±
        mlflow.set_tag("experiment_id", "exp008")
        mlflow.set_tag("description", "Ultra-Optimized LightGBM - Target 11.70 Score")
        mlflow.set_tag("approach", "Optuna + DART + Ugly Ducklings + Advanced FE")
        mlflow.set_tag("date", datetime.now().strftime("%Y-%m-%d"))
        mlflow.set_tag("inspiration", "masaishi notebook analysis")
        
        # ãƒ¢ãƒ‡ãƒ«è¨­å®š
        mlflow.log_param("model", "LightGBM Single Model")
        mlflow.log_param("optimization", "Optuna TPE Sampler (50 trials)")
        mlflow.log_param("boosting_options", "GBDT and DART with dropout")
        mlflow.log_param("cv_strategy", "5-fold KFold")
        mlflow.log_param("early_stopping", "150 rounds")
        mlflow.log_param("max_estimators", 2000)
        
        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        feature_engineering = {
            "basic_transforms": [
                "Log transformations (Episode_Length, Popularity, Ads)",
                "Time-based features (Is_Weekend, Publication_Time_ord)",
                "Sentiment encoding (0,1,2)"
            ],
            "density_features": [
                "Ads_per_Minute",
                "Host_Pop_per_Minute", 
                "Guest_Pop_per_Minute",
                "Pop_Density"
            ],
            "interaction_features": [
                "Length_Host_Int",
                "Length_Guest_Int",
                "Pop_Ads_Int",
                "Sentiment_Pop_Int",
                "Weekend_Pop_Int"
            ],
            "ugly_ducklings": [
                "Length_vs_Genre (deviation from genre mean)",
                "Host_vs_Genre",
                "Guest_vs_Genre"
            ],
            "group_statistics": [
                "Genre_*_mean/std/median",
                "Podcast_*_mean/std",
                "Target encoding with mean/std"
            ],
            "ratio_features": [
                "Pop_Balance (Host/Guest ratio)",
                "Length_Genre_ratio",
                "Pop_Genre_ratio"
            ]
        }
        
        mlflow.log_param("feature_groups", json.dumps(feature_engineering))
        mlflow.log_param("categorical_encoding", "Label Encoding (LightGBM optimized)")
        mlflow.log_param("missing_values", "-999 (LightGBM recommended)")
        
        # Optunaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“
        param_space = {
            "boosting_type": ["gbdt", "dart"],
            "num_leaves": "20-300",
            "learning_rate": "0.005-0.1 (log scale)",
            "feature_fraction": "0.6-1.0",
            "bagging_fraction": "0.6-1.0",
            "bagging_freq": "1-7",
            "max_depth": "3-15",
            "min_data_in_leaf": "10-100",
            "reg_alpha": "0.0-10.0",
            "reg_lambda": "0.0-10.0",
            "drop_rate": "0.05-0.2 (DART only)",
            "skip_drop": "0.3-0.7 (DART only)"
        }
        
        mlflow.log_param("optuna_param_space", json.dumps(param_space))
        mlflow.log_param("sampler", "TPESampler with seed=42")
        mlflow.log_param("optimization_trials", 50)
        mlflow.log_param("optimization_cv", "3-fold (for speed)")
        
        # æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„
        expected_improvements = {
            "from_research": "30-85% RMSE improvement over baseline",
            "target_score": "11.70 (masaishi level)",
            "vs_current_best": "12.94051 -> ~11.70 (21% improvement)",
            "techniques": [
                "Optuna optimization (biggest impact)",
                "DART boosting (overfitting prevention)", 
                "Ugly Ducklings (group deviations)",
                "Advanced interactions",
                "LightGBM-specific preprocessing"
            ]
        }
        
        mlflow.set_tag("expected_improvements", json.dumps(expected_improvements))
        
        # ç ”ç©¶ãƒ™ãƒ¼ã‚¹æŠ€è¡“
        research_techniques = {
            "source": "2024-2025 Kaggle Competition Best Practices",
            "key_papers": [
                "ISIC2024 2nd Place Solution",
                "Tabular Playground Series Winners",
                "LightGBM Advanced Techniques Survey"
            ],
            "validation": [
                "Proven 30-85% RMSE improvements",
                "Top Kaggle competition results",
                "RMSE as low as 5.82 in similar problems"
            ]
        }
        
        mlflow.set_tag("research_basis", json.dumps(research_techniques))
        
        # å®Ÿé¨“ç›®æ¨™
        mlflow.set_tag("primary_goal", "Achieve Public Score < 12.0")
        mlflow.set_tag("stretch_goal", "Achieve masaishi-level 11.70 score")
        mlflow.set_tag("technique_validation", "Test Optuna + DART effectiveness")
        
        print(f"âœ“ exp008ã‚’MLflowã«è¨˜éŒ²: {run_name}")
        print(f"âœ“ Ultra-optimizationæˆ¦ç•¥ã‚’è¨˜éŒ²")
        print(f"âœ“ ç ”ç©¶ãƒ™ãƒ¼ã‚¹æŠ€è¡“ã‚’è¨˜éŒ²")
        print(f"âœ“ ç›®æ¨™: masaishiç´š11.70ã‚¹ã‚³ã‚¢")
        
        run_id = mlflow.active_run().info.run_id
        
        # URLç”Ÿæˆãƒ»è¡¨ç¤º
        urls = get_experiment_url(run_id=run_id, experiment_path=experiment_path, environment=environment)
        if "run_message" in urls:
            print(urls["run_message"])
        if "exp_message" in urls:
            print(urls["exp_message"])
        
        return run_id

if __name__ == "__main__":
    run_id = log_exp008_to_mlflow()
    print(f"\nMLflow Run ID: {run_id}")
    print("ç­‹è‚‰ã®ã‚ˆã†ãªæœ€é©åŒ–å®Ÿé¨“æº–å‚™å®Œäº†ðŸ’ª")